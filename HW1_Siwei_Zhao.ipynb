{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "HW_Siwei_Zhao.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v69Cnnqq_RFB"
      },
      "source": [
        "# CS 6140 Machine Learning: Assignment - 1 (Total Points: 100)\n",
        "## Prof. Ahmad Uzair "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygWT6Kb4_T3X"
      },
      "source": [
        "Siwei ZHao"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqa5_lJW_RFE"
      },
      "source": [
        "### Q1. Classification Trees with numerical features (45 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzTp6QNg_RFE"
      },
      "source": [
        "### Datasets used for the problem:\n",
        "\n",
        "Iris: has three classes and the task is to accurately predict one of the three sub-types of the Iris flower given four different physical features. These features include the length and width of the sepals and the petals. There are a total of 150 instances with each class having 50 instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzrd3iz4_RFE"
      },
      "source": [
        "### Growing Decison Trees \n",
        "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal of this question in the assignment is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. \n",
        "\n",
        "<i>Note: Write in your code only in the place holders where you are instructed to, replacing None.<i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9fWCJm_RFF"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib notebook"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMdM53DQFAsi"
      },
      "source": [
        "# Change it to inline to show the plots\n",
        "%matplotlib inline"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vlKYvw-_RFF"
      },
      "source": [
        "### Here is the first look at your dataset and its feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqjAo6c2_RFG"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "iris_data = pd.read_csv(\"iris.csv\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khJVb6DD_RFG"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "iris_data.drop(\"Id\", axis=1, inplace=True)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "n8h_niXk_RFG",
        "outputId": "bc0c9d7b-c883-44ee-c20c-220926ae0b4d"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "iris_data.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGZFtBie_RFG",
        "outputId": "42cd2160-ee72-4461-fabf-c00aad93ac5d"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "iris_data.info()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   SepalLengthCm  150 non-null    float64\n",
            " 1   SepalWidthCm   150 non-null    float64\n",
            " 2   PetalLengthCm  150 non-null    float64\n",
            " 3   PetalWidthCm   150 non-null    float64\n",
            " 4   Species        150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "lvtWzDFL_RFH",
        "outputId": "a7b99253-b656-4538-9a86-feccbebb2594"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "iris_data.describe()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.054000</td>\n",
              "      <td>3.758667</td>\n",
              "      <td>1.198667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.433594</td>\n",
              "      <td>1.764420</td>\n",
              "      <td>0.763161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
              "count     150.000000    150.000000     150.000000    150.000000\n",
              "mean        5.843333      3.054000       3.758667      1.198667\n",
              "std         0.828066      0.433594       1.764420      0.763161\n",
              "min         4.300000      2.000000       1.000000      0.100000\n",
              "25%         5.100000      2.800000       1.600000      0.300000\n",
              "50%         5.800000      3.000000       4.350000      1.300000\n",
              "75%         6.400000      3.300000       5.100000      1.800000\n",
              "max         7.900000      4.400000       6.900000      2.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRJNjxLS_RFH"
      },
      "source": [
        "### Task\n",
        "Shuffle the data and change the categorical features mentioned in the species column to numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC6bbFLz_RFH"
      },
      "source": [
        "# Start code here\n",
        "# Replace the categorical target values in the Species column to numeric\n",
        "iris_data = iris_data.replace({'Species': {'Iris-setosa': 1, 'Iris-versicolor': 2, 'Iris-virginica': 3}})\n",
        "# Shuffle the data\n",
        "iris_data = iris_data.sample(frac = 1)\n",
        "# End code here"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KB8RSxIp_RFH",
        "outputId": "0bd62ee4-ea3d-414a-b829-4df864442ea4"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "iris_data.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>6.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
              "82             5.8           2.7            3.9           1.2        2\n",
              "112            6.8           3.0            5.5           2.1        3\n",
              "33             5.5           4.2            1.4           0.2        1\n",
              "17             5.1           3.5            1.4           0.3        1\n",
              "101            5.8           2.7            5.1           1.9        3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkkNdFSF_RFH"
      },
      "source": [
        "### Task\n",
        "Time to code your decision tree.\n",
        "\n",
        "In the following cell, create a node class for your Decision Tree Classifier having the following attributes:\n",
        "feature_index, threshold, left, right, info_gain, value, where the condition upon which the decision will be based would be defined by feature_index and threshold, while the attributes left and right will be for accessing the left and the right child of a particular node other than the leaf node in the decision tree. info_gain will denote the information gained by the split denoted by the particular decision node. The value attribute will be holding the value of the majority class of the leaf node without having the other attributes. This will help us to determine the class of new data point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw_EwLnK_RFI"
      },
      "source": [
        "class Node:  \n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        # Start code here\n",
        "        # for decision node\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        \n",
        "        # for leaf node\n",
        "        self.value = value\n",
        "    # End code here"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJwnmvEU_RFI"
      },
      "source": [
        "### Task\n",
        "In the following cell, you will create a Decision Tree Classifier from scratch class having the following attributes: root, min_samples_split, max_depth. Other instructions have been given in doc strings and comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBT7a-16_RFI"
      },
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        # Start code here\n",
        "        # Initialize the root of the decision tree to traverse through the decision tree to None\n",
        "        self.root = Node()\n",
        "        # initialize the stopping conditions\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        # End code here \n",
        "        \n",
        "        \n",
        "    def build_tree(self, dataset, curr_depth = 0):\n",
        "        \"\"\"\n",
        "        This will be a recursive function to build the decision tree.\n",
        "        dataset: The data that you will be using for your assignment\n",
        "        curr_depth: Current depth of the tree\n",
        "        Returns the leaf node\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        # Separate the features and targets into two variables X and Y\n",
        "        X = dataset.drop(['Species'], axis=1)\n",
        "        Y = dataset['Species']\n",
        "        # Extract the number of samples and number of features\n",
        "        num_samples = len(X)\n",
        "        num_features = len(dataset.columns) - 1\n",
        "        \n",
        "        # split until stopping conditions are met\n",
        "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
        "            # finding the best split\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            # check if information gain is positive\n",
        "            if best_split[\"info_gain\"] > 0:\n",
        "                # recur left\n",
        "                left_subtree = self.build_tree(best_split['dataset_left'], curr_depth + 1)\n",
        "                # recur right\n",
        "                right_subtree = self.build_tree(best_split['dataset_right'], curr_depth + 1)\n",
        "                # return the decision node in the form of a dictionary\n",
        "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
        "                           left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "        # compute leaf node\n",
        "        leaf_value = self.calculate_leaf_value(Y)\n",
        "        # End code here\n",
        "        return Node(value=leaf_value)\n",
        "    \n",
        "        \n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        \"\"\"\n",
        "        Function to find out the best split\n",
        "        dataset: input data\n",
        "        num_samples: Number of samples present in the dataset\n",
        "        num_features: Number of features in the dataset\n",
        "        Returns the best split\n",
        "        \"\"\"\n",
        "        \n",
        "        # dictionary to store the best split\n",
        "        best_split = {}\n",
        "        max_info_gain = -float(\"inf\")\n",
        "        \n",
        "        # Start code here\n",
        "        # loop over all the features in the data\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset.iloc[:, feature_index]\n",
        "            # Hint: You can use np.unique function to retrieve the values of the possible threshold\n",
        "            possible_thresholds = feature_values.unique()\n",
        "            # loop over all the feature values present in the data\n",
        "            for threshold in possible_thresholds:\n",
        "                # get current split\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                # check if children are not null\n",
        "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
        "                    y = dataset['Species']\n",
        "                    left_y = dataset_left['Species']\n",
        "                    right_y = dataset_right['Species']\n",
        "                    # compute information gain\n",
        "                    curr_info_gain = self.information_gain(y, left_y, right_y)\n",
        "                    # update the best split if needed\n",
        "                    if curr_info_gain > max_info_gain:\n",
        "                        best_split[\"feature_index\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"dataset_left\"] = dataset_left\n",
        "                        best_split[\"dataset_right\"] = dataset_right\n",
        "                        best_split[\"info_gain\"] = curr_info_gain\n",
        "                        max_info_gain = curr_info_gain\n",
        "        # End code here\n",
        "\n",
        "        return best_split\n",
        "                    \n",
        "                    \n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        \"\"\"\n",
        "        Function to split the data to the left child and right child in the decision tree\n",
        "        dataset: input data\n",
        "        feature_index: feature index used to locate the index of the feature in a particular row in the dataset\n",
        "        threshold: threshold value based on which the split will be calculated\n",
        "        Returns the left and right datavalues from the dataset\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        # Hint: Use list comprehension to distinguish which values would be present in left and right \n",
        "        # subtree on the basis of threshold\n",
        "        dataset_left = dataset[dataset.iloc[:, feature_index] < threshold]\n",
        "        dataset_right = dataset[dataset.iloc[:, feature_index] >= threshold]\n",
        "        # End code here\n",
        "        return dataset_left, dataset_right\n",
        "        \n",
        "        \n",
        "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
        "        \"\"\"\n",
        "        Function to calculate information gain. This function subtracts the combined information \n",
        "        of the child node from the parent node.\n",
        "        parent: value of parent node\n",
        "        l_child: value of left child node\n",
        "        r_child: value of right child node\n",
        "        mode: based on which information gain will be calculated either entropy/gini index\n",
        "        Returns the information gain\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        # Calculate the relative sizes of the child node with respect to the parent node\n",
        "        weight_l = self.entropy(l_child) * len(l_child) / len(parent)\n",
        "        weight_r = self.entropy(r_child) * len(r_child) / len(parent)\n",
        "        # Calculate gain on the with respect to the information gain parameter which will either be \n",
        "        # gini_index or entropy\n",
        "        if mode == \"gini\":\n",
        "            gain = self.gini_index(parent) - weight_l - weight_r\n",
        "        else:\n",
        "            gain = self.entropy(parent) - weight_l - weight_r \n",
        "        # End code here\n",
        "        return gain\n",
        "    \n",
        "    def entropy(self, y):\n",
        "        \"\"\"\n",
        "        Function to calculate the entropy\n",
        "        y: target labels\n",
        "        Returns entropy\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        # Extract the class labels\n",
        "        class_labels = np.unique(y)\n",
        "        # Initialize the entropy\n",
        "        entropy = 0\n",
        "        # Calculate the entropy\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y==cls]) / len(y)\n",
        "            entropy += (-p_cls*np.log2(p_cls))\n",
        "        # End code here\n",
        "        return entropy\n",
        "    \n",
        "    \n",
        "    def gini_index(self, y):\n",
        "        \"\"\"\n",
        "        Function to calculate gini index\n",
        "        y: target labels\n",
        "        Returns gini index\n",
        "        \"\"\"\n",
        "        # Extract the class labels\n",
        "        class_labels = np.unique(y)\n",
        "        # Initialize the gini_index\n",
        "        gini = 0\n",
        "        # Calculate the gini index\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y==cls]) / len(y)\n",
        "            gini += p_cls ** 2\n",
        "        return 1 - gini\n",
        "    \n",
        "    \n",
        "    def calculate_leaf_value(self, Y):\n",
        "        \"\"\"\n",
        "        Function to compute thr value of leaf node\n",
        "        Y: target labels\n",
        "        Returns leaf node value\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        # Return the most occuring element in Y. Hint: you can use lists \n",
        "        Y_value = np.argmax(np.bincount(Y))\n",
        "        return Y_value\n",
        "        # End code here\n",
        "    \n",
        "    def print_tree(self, tree = None, indent = \" \"):\n",
        "        \"\"\"\n",
        "        Function to print the tree. Use the pre-order traversal method to print the decision tree.\n",
        "        # Do not make any changes in this function\n",
        "        \"\"\"\n",
        "        \n",
        "        if not tree:\n",
        "            tree = self.root\n",
        "        \n",
        "        if tree.value is not None:\n",
        "            print(tree.value)\n",
        "            \n",
        "        else:\n",
        "            print(\"X \" + str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
        "            print(\"%sleft:\" % (indent), end = \" \")\n",
        "            self.print_tree(tree.left, indent + indent)\n",
        "            print(\"%sright\" % (indent), end = \" \")\n",
        "            self.print_tree(tree.right, indent + indent)\n",
        "            \n",
        "            \n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "        Function to train the tree.\n",
        "        X: Features\n",
        "        Y: Target\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        # Concatenate X, Y to create the dataset and call the build_tree function recursively\n",
        "        dataset = np.concatenate([X, Y], axis=1)\n",
        "        dataset = pd.DataFrame(dataset, columns = iris_data.columns)\n",
        "        self.root = self.build_tree(dataset, 0)\n",
        "        # End code here\n",
        "        \n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Prediction function to calculate the all the predictions of the matrix of features \n",
        "        provided using make_predictions function\n",
        "        X: Matrix of features\n",
        "        Returns predictions using the make_predictions function\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            predictions.append(self.make_predictions(x, self.root))\n",
        "        # End code here\n",
        "        return predictions\n",
        "    \n",
        "    \n",
        "    def make_predictions(self, x, tree):\n",
        "        \"\"\"\n",
        "        Function to predict a single datapoint\n",
        "        x: data\n",
        "        tree: current tree\n",
        "        Returns predictions\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        # return the value if the node is a leaf node\n",
        "        if tree.value != None:\n",
        "            return tree.value\n",
        "        # Extract feature values of a new datapoint at a given feature index\n",
        "        feature_val = x[tree.feature_index]\n",
        "        # Recur through left or right subtree \n",
        "        if feature_val < tree.threshold:\n",
        "            return self.make_predictions(x, tree.left)\n",
        "        return self.make_predictions(x, tree.right)\n",
        "      # End code here\n",
        " "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlhExBdR_RFL"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-If3DTP_RFM",
        "outputId": "9c1f0836-51ec-466f-ef69-0846c3e1a998"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "X = iris_data.iloc[:, :-1].values\n",
        "Y = iris_data.iloc[:, -1].values.reshape(-1, 1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 41)\n",
        "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
        "classifier.fit(X_train, Y_train)\n",
        "classifier.print_tree()\n",
        "y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy is: \"+str(accuracy_score(Y_test, y_pred)))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X 2 <= 3.0 ? 0.9340680553754911\n",
            " left: 1\n",
            " right X 3 <= 1.8 ? 0.7118632793592745\n",
            "  left: X 2 <= 5.0 ? 0.2339413232514668\n",
            "    left: X 3 <= 1.7 ? 0.17556502585750278\n",
            "        left: 2\n",
            "        right 3\n",
            "    right X 3 <= 1.6 ? 0.4591479170272448\n",
            "        left: 3\n",
            "        right 2\n",
            "  right 3\n",
            "Accuracy is: 0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xChs8sf5_RFM"
      },
      "source": [
        "### Q2. Regression (35 points)\n",
        "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. \n",
        "\n",
        "Ridge regression is a method of estimating the coefficients of multiple-regression models in scenarios where independent variables are highly correlated. \n",
        "\n",
        "Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent.\n",
        "\n",
        "The goal of this question in the assignment is to create a model that predicts the value of a target variable by learning the relationship between independent and its corresponding dependent variable using linear regression, ridge regression and gradient descent.  \n",
        "\n",
        "<i>Note: Write in your code only in the place holders where you are instructed to, replacing None.<i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onvqgN6T_RFM"
      },
      "source": [
        "## Gradient descent algorithm \n",
        "\\begin{equation}\n",
        "\\theta^{+} = \\theta^{-} + \\frac{\\alpha}{m} (y_{i} - h(x_{i}) )\\bar{x}\n",
        "\\end{equation}\n",
        "\n",
        "This minimizes the following cost function\n",
        "\n",
        "\\begin{equation}\n",
        "J(x, \\theta, y) = \\frac{1}{2m}\\sum_{i=1}^{m}(h(x_i) - y_i)^2\n",
        "\\end{equation}\n",
        "\n",
        "where\n",
        "\\begin{equation}\n",
        "h(x_i) = \\theta^T \\bar{x}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0rB5inN_RFM"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "true_slope = 15\n",
        "true_intercept = 2.4\n",
        "input_var = np.arange(0.0,100.0)\n",
        "output_var = true_slope * input_var + true_intercept + 300.0 * np.random.rand(len(input_var))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "aK2wQxIu_RFN",
        "outputId": "5a040d1e-a10f-409d-c4db-7ad105e0d19f"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "plt.figure()\n",
        "plt.scatter(input_var, output_var)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQXioh2k_RFN"
      },
      "source": [
        "def compute_cost(ip, op, params):\n",
        "    \"\"\"\n",
        "    Cost function in linear regression where the cost is calculated\n",
        "    ip: input variables\n",
        "    op: output variables\n",
        "    params: corresponding parameters\n",
        "    Returns cost\n",
        "    \"\"\"\n",
        "    # Start code here\n",
        "    num_samples = len(op)\n",
        "    cost_sum = 0\n",
        "    for x, y in zip(ip, op):\n",
        "        y_hat = params[0] + params[1] * x\n",
        "        cost_sum += (y - y_hat)**2\n",
        "\n",
        "    cost = cost_sum / num_samples / 2\n",
        "    # End code here\n",
        "    return cost"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2_EkGvJ_RFN"
      },
      "source": [
        "\n",
        "### Batch gradient descent\n",
        "Algorithm can be given as follows:\n",
        "\n",
        "```for j in 0 -> max_iteration: \n",
        "    for i in 0 -> m: \n",
        "        theta += (alpha / m) * (y[i] - h(x[i])) * x_bar\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d03QYmiU_RFO"
      },
      "source": [
        "def linear_regression_using_batch_gradient_descent(ip, op, params, alpha, max_iter):\n",
        "    \"\"\"\n",
        "    Compute the params for linear regression using batch gradient descent\n",
        "    ip: input variables\n",
        "    op: output variables\n",
        "    params: corresponding parameters\n",
        "    alpha: learning rate\n",
        "    max_iter: maximum number of iterations\n",
        "    Returns parameters, cost, params_store\n",
        "    \"\"\" \n",
        "    # Start code here\n",
        "    # initialize iteration, number of samples, cost and parameter array\n",
        "    iteration = 0\n",
        "    num_samples = len(op)\n",
        "    cost = np.zeros(max_iter)\n",
        "    params_store = np.zeros((2, max_iter))\n",
        "    \n",
        "    # Compute the cost and store the params for the corresponding cost\n",
        "    while iteration < max_iter:\n",
        "        cost[iteration] = compute_cost(ip, op, params)\n",
        "        params_store[:, iteration] = params\n",
        "        \n",
        "        print('--------------------------')\n",
        "        print(f'iteration: {iteration}')\n",
        "        print(f'cost: {cost[iteration]}')\n",
        "        \n",
        "        gradient_0 = 0\n",
        "        gradient_1 = 0\n",
        "        # Apply batch gradient descent\n",
        "        for x,y in zip(ip, op):\n",
        "            y_hat = params[0] + params[1] * x\n",
        "            gradient_0 += (y_hat - y) / num_samples\n",
        "            gradient_1 += (y_hat - y) * x / num_samples\n",
        "\n",
        "        params[0] = params[0] - alpha * gradient_0 / 2\n",
        "        params[1] = params[1] - alpha * gradient_1 / 2    \n",
        "        iteration += 1\n",
        "    # End code here\n",
        "    \n",
        "    return params, cost, params_store"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-PpiswU_RFO",
        "outputId": "d76039a9-6f27-4a22-e3b2-ff34172645d7"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "# Training the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(input_var, output_var, test_size=0.20)\n",
        "\n",
        "params_0 = np.array([20.0, 80.0])\n",
        "\n",
        "alpha_batch = 1e-3\n",
        "max_iter = 500\n",
        "params_hat_batch, cost_batch, params_store_batch =\\\n",
        "    linear_regression_using_batch_gradient_descent(x_train, y_train, params_0, alpha_batch, max_iter)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------\n",
            "iteration: 0\n",
            "cost: 6574048.46460789\n",
            "--------------------------\n",
            "iteration: 1\n",
            "cost: 2822719.1241101627\n",
            "--------------------------\n",
            "iteration: 2\n",
            "cost: 1214295.806560119\n",
            "--------------------------\n",
            "iteration: 3\n",
            "cost: 524666.5732644859\n",
            "--------------------------\n",
            "iteration: 4\n",
            "cost: 228980.21956219818\n",
            "--------------------------\n",
            "iteration: 5\n",
            "cost: 102201.12711900008\n",
            "--------------------------\n",
            "iteration: 6\n",
            "cost: 47842.8459289505\n",
            "--------------------------\n",
            "iteration: 7\n",
            "cost: 24535.769244177784\n",
            "--------------------------\n",
            "iteration: 8\n",
            "cost: 14542.231699550655\n",
            "--------------------------\n",
            "iteration: 9\n",
            "cost: 10257.017840074957\n",
            "--------------------------\n",
            "iteration: 10\n",
            "cost: 8419.309461860566\n",
            "--------------------------\n",
            "iteration: 11\n",
            "cost: 7630.995568335628\n",
            "--------------------------\n",
            "iteration: 12\n",
            "cost: 7292.620980904698\n",
            "--------------------------\n",
            "iteration: 13\n",
            "cost: 7147.162822238795\n",
            "--------------------------\n",
            "iteration: 14\n",
            "cost: 7084.419759798699\n",
            "--------------------------\n",
            "iteration: 15\n",
            "cost: 7057.141782911526\n",
            "--------------------------\n",
            "iteration: 16\n",
            "cost: 7045.069939542251\n",
            "--------------------------\n",
            "iteration: 17\n",
            "cost: 7039.517985341628\n",
            "--------------------------\n",
            "iteration: 18\n",
            "cost: 7036.761599276464\n",
            "--------------------------\n",
            "iteration: 19\n",
            "cost: 7035.203938485759\n",
            "--------------------------\n",
            "iteration: 20\n",
            "cost: 7034.160339335147\n",
            "--------------------------\n",
            "iteration: 21\n",
            "cost: 7033.337244878191\n",
            "--------------------------\n",
            "iteration: 22\n",
            "cost: 7032.608789381836\n",
            "--------------------------\n",
            "iteration: 23\n",
            "cost: 7031.921006530521\n",
            "--------------------------\n",
            "iteration: 24\n",
            "cost: 7031.250757659924\n",
            "--------------------------\n",
            "iteration: 25\n",
            "cost: 7030.588121793871\n",
            "--------------------------\n",
            "iteration: 26\n",
            "cost: 7029.9288451826815\n",
            "--------------------------\n",
            "iteration: 27\n",
            "cost: 7029.271103961136\n",
            "--------------------------\n",
            "iteration: 28\n",
            "cost: 7028.614116103277\n",
            "--------------------------\n",
            "iteration: 29\n",
            "cost: 7027.957546282931\n",
            "--------------------------\n",
            "iteration: 30\n",
            "cost: 7027.301250701307\n",
            "--------------------------\n",
            "iteration: 31\n",
            "cost: 7026.645167679046\n",
            "--------------------------\n",
            "iteration: 32\n",
            "cost: 7025.989270746383\n",
            "--------------------------\n",
            "iteration: 33\n",
            "cost: 7025.333548530069\n",
            "--------------------------\n",
            "iteration: 34\n",
            "cost: 7024.67799612963\n",
            "--------------------------\n",
            "iteration: 35\n",
            "cost: 7024.022611419906\n",
            "--------------------------\n",
            "iteration: 36\n",
            "cost: 7023.367393465647\n",
            "--------------------------\n",
            "iteration: 37\n",
            "cost: 7022.71234184182\n",
            "--------------------------\n",
            "iteration: 38\n",
            "cost: 7022.057456342164\n",
            "--------------------------\n",
            "iteration: 39\n",
            "cost: 7021.402736854211\n",
            "--------------------------\n",
            "iteration: 40\n",
            "cost: 7020.748183305719\n",
            "--------------------------\n",
            "iteration: 41\n",
            "cost: 7020.093795641701\n",
            "--------------------------\n",
            "iteration: 42\n",
            "cost: 7019.439573814573\n",
            "--------------------------\n",
            "iteration: 43\n",
            "cost: 7018.785517779928\n",
            "--------------------------\n",
            "iteration: 44\n",
            "cost: 7018.131627494736\n",
            "--------------------------\n",
            "iteration: 45\n",
            "cost: 7017.477902916557\n",
            "--------------------------\n",
            "iteration: 46\n",
            "cost: 7016.824344003202\n",
            "--------------------------\n",
            "iteration: 47\n",
            "cost: 7016.170950712617\n",
            "--------------------------\n",
            "iteration: 48\n",
            "cost: 7015.517723002794\n",
            "--------------------------\n",
            "iteration: 49\n",
            "cost: 7014.864660831755\n",
            "--------------------------\n",
            "iteration: 50\n",
            "cost: 7014.211764157548\n",
            "--------------------------\n",
            "iteration: 51\n",
            "cost: 7013.559032938223\n",
            "--------------------------\n",
            "iteration: 52\n",
            "cost: 7012.906467131857\n",
            "--------------------------\n",
            "iteration: 53\n",
            "cost: 7012.254066696524\n",
            "--------------------------\n",
            "iteration: 54\n",
            "cost: 7011.6018315903275\n",
            "--------------------------\n",
            "iteration: 55\n",
            "cost: 7010.949761771364\n",
            "--------------------------\n",
            "iteration: 56\n",
            "cost: 7010.2978571977455\n",
            "--------------------------\n",
            "iteration: 57\n",
            "cost: 7009.646117827588\n",
            "--------------------------\n",
            "iteration: 58\n",
            "cost: 7008.994543619045\n",
            "--------------------------\n",
            "iteration: 59\n",
            "cost: 7008.343134530248\n",
            "--------------------------\n",
            "iteration: 60\n",
            "cost: 7007.691890519355\n",
            "--------------------------\n",
            "iteration: 61\n",
            "cost: 7007.040811544539\n",
            "--------------------------\n",
            "iteration: 62\n",
            "cost: 7006.389897563968\n",
            "--------------------------\n",
            "iteration: 63\n",
            "cost: 7005.739148535834\n",
            "--------------------------\n",
            "iteration: 64\n",
            "cost: 7005.088564418341\n",
            "--------------------------\n",
            "iteration: 65\n",
            "cost: 7004.438145169683\n",
            "--------------------------\n",
            "iteration: 66\n",
            "cost: 7003.787890748092\n",
            "--------------------------\n",
            "iteration: 67\n",
            "cost: 7003.137801111798\n",
            "--------------------------\n",
            "iteration: 68\n",
            "cost: 7002.487876219033\n",
            "--------------------------\n",
            "iteration: 69\n",
            "cost: 7001.838116028058\n",
            "--------------------------\n",
            "iteration: 70\n",
            "cost: 7001.188520497133\n",
            "--------------------------\n",
            "iteration: 71\n",
            "cost: 7000.539089584522\n",
            "--------------------------\n",
            "iteration: 72\n",
            "cost: 6999.889823248518\n",
            "--------------------------\n",
            "iteration: 73\n",
            "cost: 6999.240721447405\n",
            "--------------------------\n",
            "iteration: 74\n",
            "cost: 6998.5917841395\n",
            "--------------------------\n",
            "iteration: 75\n",
            "cost: 6997.943011283109\n",
            "--------------------------\n",
            "iteration: 76\n",
            "cost: 6997.294402836555\n",
            "--------------------------\n",
            "iteration: 77\n",
            "cost: 6996.64595875818\n",
            "--------------------------\n",
            "iteration: 78\n",
            "cost: 6995.997679006325\n",
            "--------------------------\n",
            "iteration: 79\n",
            "cost: 6995.349563539354\n",
            "--------------------------\n",
            "iteration: 80\n",
            "cost: 6994.701612315625\n",
            "--------------------------\n",
            "iteration: 81\n",
            "cost: 6994.053825293518\n",
            "--------------------------\n",
            "iteration: 82\n",
            "cost: 6993.406202431438\n",
            "--------------------------\n",
            "iteration: 83\n",
            "cost: 6992.758743687761\n",
            "--------------------------\n",
            "iteration: 84\n",
            "cost: 6992.111449020906\n",
            "--------------------------\n",
            "iteration: 85\n",
            "cost: 6991.464318389296\n",
            "--------------------------\n",
            "iteration: 86\n",
            "cost: 6990.817351751355\n",
            "--------------------------\n",
            "iteration: 87\n",
            "cost: 6990.170549065537\n",
            "--------------------------\n",
            "iteration: 88\n",
            "cost: 6989.52391029028\n",
            "--------------------------\n",
            "iteration: 89\n",
            "cost: 6988.877435384051\n",
            "--------------------------\n",
            "iteration: 90\n",
            "cost: 6988.231124305329\n",
            "--------------------------\n",
            "iteration: 91\n",
            "cost: 6987.584977012591\n",
            "--------------------------\n",
            "iteration: 92\n",
            "cost: 6986.938993464324\n",
            "--------------------------\n",
            "iteration: 93\n",
            "cost: 6986.2931736190485\n",
            "--------------------------\n",
            "iteration: 94\n",
            "cost: 6985.64751743527\n",
            "--------------------------\n",
            "iteration: 95\n",
            "cost: 6985.002024871514\n",
            "--------------------------\n",
            "iteration: 96\n",
            "cost: 6984.3566958863175\n",
            "--------------------------\n",
            "iteration: 97\n",
            "cost: 6983.711530438233\n",
            "--------------------------\n",
            "iteration: 98\n",
            "cost: 6983.066528485802\n",
            "--------------------------\n",
            "iteration: 99\n",
            "cost: 6982.421689987605\n",
            "--------------------------\n",
            "iteration: 100\n",
            "cost: 6981.777014902221\n",
            "--------------------------\n",
            "iteration: 101\n",
            "cost: 6981.132503188227\n",
            "--------------------------\n",
            "iteration: 102\n",
            "cost: 6980.488154804237\n",
            "--------------------------\n",
            "iteration: 103\n",
            "cost: 6979.843969708849\n",
            "--------------------------\n",
            "iteration: 104\n",
            "cost: 6979.199947860684\n",
            "--------------------------\n",
            "iteration: 105\n",
            "cost: 6978.5560892183785\n",
            "--------------------------\n",
            "iteration: 106\n",
            "cost: 6977.912393740566\n",
            "--------------------------\n",
            "iteration: 107\n",
            "cost: 6977.268861385904\n",
            "--------------------------\n",
            "iteration: 108\n",
            "cost: 6976.625492113051\n",
            "--------------------------\n",
            "iteration: 109\n",
            "cost: 6975.982285880686\n",
            "--------------------------\n",
            "iteration: 110\n",
            "cost: 6975.339242647479\n",
            "--------------------------\n",
            "iteration: 111\n",
            "cost: 6974.696362372136\n",
            "--------------------------\n",
            "iteration: 112\n",
            "cost: 6974.053645013353\n",
            "--------------------------\n",
            "iteration: 113\n",
            "cost: 6973.411090529846\n",
            "--------------------------\n",
            "iteration: 114\n",
            "cost: 6972.768698880344\n",
            "--------------------------\n",
            "iteration: 115\n",
            "cost: 6972.126470023575\n",
            "--------------------------\n",
            "iteration: 116\n",
            "cost: 6971.484403918286\n",
            "--------------------------\n",
            "iteration: 117\n",
            "cost: 6970.842500523239\n",
            "--------------------------\n",
            "iteration: 118\n",
            "cost: 6970.200759797194\n",
            "--------------------------\n",
            "iteration: 119\n",
            "cost: 6969.559181698931\n",
            "--------------------------\n",
            "iteration: 120\n",
            "cost: 6968.917766187241\n",
            "--------------------------\n",
            "iteration: 121\n",
            "cost: 6968.276513220912\n",
            "--------------------------\n",
            "iteration: 122\n",
            "cost: 6967.63542275876\n",
            "--------------------------\n",
            "iteration: 123\n",
            "cost: 6966.994494759604\n",
            "--------------------------\n",
            "iteration: 124\n",
            "cost: 6966.3537291822695\n",
            "--------------------------\n",
            "iteration: 125\n",
            "cost: 6965.7131259856005\n",
            "--------------------------\n",
            "iteration: 126\n",
            "cost: 6965.072685128439\n",
            "--------------------------\n",
            "iteration: 127\n",
            "cost: 6964.432406569659\n",
            "--------------------------\n",
            "iteration: 128\n",
            "cost: 6963.792290268114\n",
            "--------------------------\n",
            "iteration: 129\n",
            "cost: 6963.152336182697\n",
            "--------------------------\n",
            "iteration: 130\n",
            "cost: 6962.512544272303\n",
            "--------------------------\n",
            "iteration: 131\n",
            "cost: 6961.872914495822\n",
            "--------------------------\n",
            "iteration: 132\n",
            "cost: 6961.233446812174\n",
            "--------------------------\n",
            "iteration: 133\n",
            "cost: 6960.5941411802805\n",
            "--------------------------\n",
            "iteration: 134\n",
            "cost: 6959.954997559078\n",
            "--------------------------\n",
            "iteration: 135\n",
            "cost: 6959.316015907502\n",
            "--------------------------\n",
            "iteration: 136\n",
            "cost: 6958.677196184518\n",
            "--------------------------\n",
            "iteration: 137\n",
            "cost: 6958.0385383490775\n",
            "--------------------------\n",
            "iteration: 138\n",
            "cost: 6957.400042360173\n",
            "--------------------------\n",
            "iteration: 139\n",
            "cost: 6956.761708176773\n",
            "--------------------------\n",
            "iteration: 140\n",
            "cost: 6956.123535757882\n",
            "--------------------------\n",
            "iteration: 141\n",
            "cost: 6955.485525062509\n",
            "--------------------------\n",
            "iteration: 142\n",
            "cost: 6954.847676049659\n",
            "--------------------------\n",
            "iteration: 143\n",
            "cost: 6954.209988678364\n",
            "--------------------------\n",
            "iteration: 144\n",
            "cost: 6953.572462907665\n",
            "--------------------------\n",
            "iteration: 145\n",
            "cost: 6952.935098696615\n",
            "--------------------------\n",
            "iteration: 146\n",
            "cost: 6952.297896004257\n",
            "--------------------------\n",
            "iteration: 147\n",
            "cost: 6951.66085478967\n",
            "--------------------------\n",
            "iteration: 148\n",
            "cost: 6951.023975011926\n",
            "--------------------------\n",
            "iteration: 149\n",
            "cost: 6950.38725663012\n",
            "--------------------------\n",
            "iteration: 150\n",
            "cost: 6949.7506996033535\n",
            "--------------------------\n",
            "iteration: 151\n",
            "cost: 6949.114303890735\n",
            "--------------------------\n",
            "iteration: 152\n",
            "cost: 6948.478069451378\n",
            "--------------------------\n",
            "iteration: 153\n",
            "cost: 6947.841996244424\n",
            "--------------------------\n",
            "iteration: 154\n",
            "cost: 6947.206084228997\n",
            "--------------------------\n",
            "iteration: 155\n",
            "cost: 6946.570333364267\n",
            "--------------------------\n",
            "iteration: 156\n",
            "cost: 6945.9347436093885\n",
            "--------------------------\n",
            "iteration: 157\n",
            "cost: 6945.299314923529\n",
            "--------------------------\n",
            "iteration: 158\n",
            "cost: 6944.664047265879\n",
            "--------------------------\n",
            "iteration: 159\n",
            "cost: 6944.028940595621\n",
            "--------------------------\n",
            "iteration: 160\n",
            "cost: 6943.393994871973\n",
            "--------------------------\n",
            "iteration: 161\n",
            "cost: 6942.759210054132\n",
            "--------------------------\n",
            "iteration: 162\n",
            "cost: 6942.124586101335\n",
            "--------------------------\n",
            "iteration: 163\n",
            "cost: 6941.490122972815\n",
            "--------------------------\n",
            "iteration: 164\n",
            "cost: 6940.855820627805\n",
            "--------------------------\n",
            "iteration: 165\n",
            "cost: 6940.221679025565\n",
            "--------------------------\n",
            "iteration: 166\n",
            "cost: 6939.587698125366\n",
            "--------------------------\n",
            "iteration: 167\n",
            "cost: 6938.953877886483\n",
            "--------------------------\n",
            "iteration: 168\n",
            "cost: 6938.320218268194\n",
            "--------------------------\n",
            "iteration: 169\n",
            "cost: 6937.686719229801\n",
            "--------------------------\n",
            "iteration: 170\n",
            "cost: 6937.053380730606\n",
            "--------------------------\n",
            "iteration: 171\n",
            "cost: 6936.420202729928\n",
            "--------------------------\n",
            "iteration: 172\n",
            "cost: 6935.7871851871\n",
            "--------------------------\n",
            "iteration: 173\n",
            "cost: 6935.154328061451\n",
            "--------------------------\n",
            "iteration: 174\n",
            "cost: 6934.5216313123365\n",
            "--------------------------\n",
            "iteration: 175\n",
            "cost: 6933.8890948991\n",
            "--------------------------\n",
            "iteration: 176\n",
            "cost: 6933.256718781125\n",
            "--------------------------\n",
            "iteration: 177\n",
            "cost: 6932.624502917779\n",
            "--------------------------\n",
            "iteration: 178\n",
            "cost: 6931.992447268461\n",
            "--------------------------\n",
            "iteration: 179\n",
            "cost: 6931.360551792559\n",
            "--------------------------\n",
            "iteration: 180\n",
            "cost: 6930.728816449495\n",
            "--------------------------\n",
            "iteration: 181\n",
            "cost: 6930.097241198678\n",
            "--------------------------\n",
            "iteration: 182\n",
            "cost: 6929.465825999544\n",
            "--------------------------\n",
            "iteration: 183\n",
            "cost: 6928.834570811532\n",
            "--------------------------\n",
            "iteration: 184\n",
            "cost: 6928.203475594091\n",
            "--------------------------\n",
            "iteration: 185\n",
            "cost: 6927.572540306683\n",
            "--------------------------\n",
            "iteration: 186\n",
            "cost: 6926.941764908779\n",
            "--------------------------\n",
            "iteration: 187\n",
            "cost: 6926.311149359858\n",
            "--------------------------\n",
            "iteration: 188\n",
            "cost: 6925.680693619412\n",
            "--------------------------\n",
            "iteration: 189\n",
            "cost: 6925.050397646948\n",
            "--------------------------\n",
            "iteration: 190\n",
            "cost: 6924.42026140197\n",
            "--------------------------\n",
            "iteration: 191\n",
            "cost: 6923.790284844011\n",
            "--------------------------\n",
            "iteration: 192\n",
            "cost: 6923.160467932592\n",
            "--------------------------\n",
            "iteration: 193\n",
            "cost: 6922.530810627267\n",
            "--------------------------\n",
            "iteration: 194\n",
            "cost: 6921.901312887579\n",
            "--------------------------\n",
            "iteration: 195\n",
            "cost: 6921.2719746731\n",
            "--------------------------\n",
            "iteration: 196\n",
            "cost: 6920.642795943395\n",
            "--------------------------\n",
            "iteration: 197\n",
            "cost: 6920.013776658055\n",
            "--------------------------\n",
            "iteration: 198\n",
            "cost: 6919.3849167766775\n",
            "--------------------------\n",
            "iteration: 199\n",
            "cost: 6918.756216258853\n",
            "--------------------------\n",
            "iteration: 200\n",
            "cost: 6918.127675064205\n",
            "--------------------------\n",
            "iteration: 201\n",
            "cost: 6917.499293152361\n",
            "--------------------------\n",
            "iteration: 202\n",
            "cost: 6916.871070482955\n",
            "--------------------------\n",
            "iteration: 203\n",
            "cost: 6916.2430070156215\n",
            "--------------------------\n",
            "iteration: 204\n",
            "cost: 6915.61510271003\n",
            "--------------------------\n",
            "iteration: 205\n",
            "cost: 6914.987357525842\n",
            "--------------------------\n",
            "iteration: 206\n",
            "cost: 6914.3597714227335\n",
            "--------------------------\n",
            "iteration: 207\n",
            "cost: 6913.732344360386\n",
            "--------------------------\n",
            "iteration: 208\n",
            "cost: 6913.105076298498\n",
            "--------------------------\n",
            "iteration: 209\n",
            "cost: 6912.477967196782\n",
            "--------------------------\n",
            "iteration: 210\n",
            "cost: 6911.8510170149475\n",
            "--------------------------\n",
            "iteration: 211\n",
            "cost: 6911.224225712724\n",
            "--------------------------\n",
            "iteration: 212\n",
            "cost: 6910.597593249852\n",
            "--------------------------\n",
            "iteration: 213\n",
            "cost: 6909.971119586078\n",
            "--------------------------\n",
            "iteration: 214\n",
            "cost: 6909.344804681156\n",
            "--------------------------\n",
            "iteration: 215\n",
            "cost: 6908.7186484948525\n",
            "--------------------------\n",
            "iteration: 216\n",
            "cost: 6908.092650986951\n",
            "--------------------------\n",
            "iteration: 217\n",
            "cost: 6907.466812117236\n",
            "--------------------------\n",
            "iteration: 218\n",
            "cost: 6906.841131845511\n",
            "--------------------------\n",
            "iteration: 219\n",
            "cost: 6906.2156101315795\n",
            "--------------------------\n",
            "iteration: 220\n",
            "cost: 6905.590246935264\n",
            "--------------------------\n",
            "iteration: 221\n",
            "cost: 6904.965042216388\n",
            "--------------------------\n",
            "iteration: 222\n",
            "cost: 6904.339995934795\n",
            "--------------------------\n",
            "iteration: 223\n",
            "cost: 6903.715108050337\n",
            "--------------------------\n",
            "iteration: 224\n",
            "cost: 6903.0903785228675\n",
            "--------------------------\n",
            "iteration: 225\n",
            "cost: 6902.465807312257\n",
            "--------------------------\n",
            "iteration: 226\n",
            "cost: 6901.841394378392\n",
            "--------------------------\n",
            "iteration: 227\n",
            "cost: 6901.217139681152\n",
            "--------------------------\n",
            "iteration: 228\n",
            "cost: 6900.5930431804445\n",
            "--------------------------\n",
            "iteration: 229\n",
            "cost: 6899.96910483618\n",
            "--------------------------\n",
            "iteration: 230\n",
            "cost: 6899.345324608276\n",
            "--------------------------\n",
            "iteration: 231\n",
            "cost: 6898.721702456665\n",
            "--------------------------\n",
            "iteration: 232\n",
            "cost: 6898.098238341287\n",
            "--------------------------\n",
            "iteration: 233\n",
            "cost: 6897.4749322220905\n",
            "--------------------------\n",
            "iteration: 234\n",
            "cost: 6896.851784059045\n",
            "--------------------------\n",
            "iteration: 235\n",
            "cost: 6896.228793812108\n",
            "--------------------------\n",
            "iteration: 236\n",
            "cost: 6895.605961441281\n",
            "--------------------------\n",
            "iteration: 237\n",
            "cost: 6894.983286906534\n",
            "--------------------------\n",
            "iteration: 238\n",
            "cost: 6894.360770167882\n",
            "--------------------------\n",
            "iteration: 239\n",
            "cost: 6893.7384111853335\n",
            "--------------------------\n",
            "iteration: 240\n",
            "cost: 6893.116209918911\n",
            "--------------------------\n",
            "iteration: 241\n",
            "cost: 6892.49416632864\n",
            "--------------------------\n",
            "iteration: 242\n",
            "cost: 6891.872280374572\n",
            "--------------------------\n",
            "iteration: 243\n",
            "cost: 6891.25055201676\n",
            "--------------------------\n",
            "iteration: 244\n",
            "cost: 6890.628981215261\n",
            "--------------------------\n",
            "iteration: 245\n",
            "cost: 6890.007567930147\n",
            "--------------------------\n",
            "iteration: 246\n",
            "cost: 6889.386312121501\n",
            "--------------------------\n",
            "iteration: 247\n",
            "cost: 6888.765213749421\n",
            "--------------------------\n",
            "iteration: 248\n",
            "cost: 6888.144272774001\n",
            "--------------------------\n",
            "iteration: 249\n",
            "cost: 6887.5234891553655\n",
            "--------------------------\n",
            "iteration: 250\n",
            "cost: 6886.902862853635\n",
            "--------------------------\n",
            "iteration: 251\n",
            "cost: 6886.282393828929\n",
            "--------------------------\n",
            "iteration: 252\n",
            "cost: 6885.66208204141\n",
            "--------------------------\n",
            "iteration: 253\n",
            "cost: 6885.041927451219\n",
            "--------------------------\n",
            "iteration: 254\n",
            "cost: 6884.421930018523\n",
            "--------------------------\n",
            "iteration: 255\n",
            "cost: 6883.802089703497\n",
            "--------------------------\n",
            "iteration: 256\n",
            "cost: 6883.182406466325\n",
            "--------------------------\n",
            "iteration: 257\n",
            "cost: 6882.562880267203\n",
            "--------------------------\n",
            "iteration: 258\n",
            "cost: 6881.9435110663235\n",
            "--------------------------\n",
            "iteration: 259\n",
            "cost: 6881.324298823917\n",
            "--------------------------\n",
            "iteration: 260\n",
            "cost: 6880.705243500194\n",
            "--------------------------\n",
            "iteration: 261\n",
            "cost: 6880.086345055393\n",
            "--------------------------\n",
            "iteration: 262\n",
            "cost: 6879.467603449765\n",
            "--------------------------\n",
            "iteration: 263\n",
            "cost: 6878.849018643554\n",
            "--------------------------\n",
            "iteration: 264\n",
            "cost: 6878.23059059703\n",
            "--------------------------\n",
            "iteration: 265\n",
            "cost: 6877.612319270469\n",
            "--------------------------\n",
            "iteration: 266\n",
            "cost: 6876.994204624149\n",
            "--------------------------\n",
            "iteration: 267\n",
            "cost: 6876.376246618374\n",
            "--------------------------\n",
            "iteration: 268\n",
            "cost: 6875.758445213438\n",
            "--------------------------\n",
            "iteration: 269\n",
            "cost: 6875.140800369666\n",
            "--------------------------\n",
            "iteration: 270\n",
            "cost: 6874.523312047377\n",
            "--------------------------\n",
            "iteration: 271\n",
            "cost: 6873.905980206908\n",
            "--------------------------\n",
            "iteration: 272\n",
            "cost: 6873.288804808602\n",
            "--------------------------\n",
            "iteration: 273\n",
            "cost: 6872.67178581281\n",
            "--------------------------\n",
            "iteration: 274\n",
            "cost: 6872.054923179903\n",
            "--------------------------\n",
            "iteration: 275\n",
            "cost: 6871.438216870256\n",
            "--------------------------\n",
            "iteration: 276\n",
            "cost: 6870.821666844255\n",
            "--------------------------\n",
            "iteration: 277\n",
            "cost: 6870.205273062289\n",
            "--------------------------\n",
            "iteration: 278\n",
            "cost: 6869.589035484771\n",
            "--------------------------\n",
            "iteration: 279\n",
            "cost: 6868.972954072111\n",
            "--------------------------\n",
            "iteration: 280\n",
            "cost: 6868.3570287847415\n",
            "--------------------------\n",
            "iteration: 281\n",
            "cost: 6867.741259583083\n",
            "--------------------------\n",
            "iteration: 282\n",
            "cost: 6867.125646427588\n",
            "--------------------------\n",
            "iteration: 283\n",
            "cost: 6866.510189278716\n",
            "--------------------------\n",
            "iteration: 284\n",
            "cost: 6865.894888096936\n",
            "--------------------------\n",
            "iteration: 285\n",
            "cost: 6865.2797428427075\n",
            "--------------------------\n",
            "iteration: 286\n",
            "cost: 6864.664753476532\n",
            "--------------------------\n",
            "iteration: 287\n",
            "cost: 6864.049919958896\n",
            "--------------------------\n",
            "iteration: 288\n",
            "cost: 6863.435242250312\n",
            "--------------------------\n",
            "iteration: 289\n",
            "cost: 6862.820720311282\n",
            "--------------------------\n",
            "iteration: 290\n",
            "cost: 6862.20635410235\n",
            "--------------------------\n",
            "iteration: 291\n",
            "cost: 6861.592143584028\n",
            "--------------------------\n",
            "iteration: 292\n",
            "cost: 6860.978088716887\n",
            "--------------------------\n",
            "iteration: 293\n",
            "cost: 6860.364189461458\n",
            "--------------------------\n",
            "iteration: 294\n",
            "cost: 6859.750445778332\n",
            "--------------------------\n",
            "iteration: 295\n",
            "cost: 6859.13685762806\n",
            "--------------------------\n",
            "iteration: 296\n",
            "cost: 6858.523424971249\n",
            "--------------------------\n",
            "iteration: 297\n",
            "cost: 6857.910147768477\n",
            "--------------------------\n",
            "iteration: 298\n",
            "cost: 6857.297025980352\n",
            "--------------------------\n",
            "iteration: 299\n",
            "cost: 6856.6840595675\n",
            "--------------------------\n",
            "iteration: 300\n",
            "cost: 6856.071248490535\n",
            "--------------------------\n",
            "iteration: 301\n",
            "cost: 6855.458592710107\n",
            "--------------------------\n",
            "iteration: 302\n",
            "cost: 6854.846092186841\n",
            "--------------------------\n",
            "iteration: 303\n",
            "cost: 6854.233746881405\n",
            "--------------------------\n",
            "iteration: 304\n",
            "cost: 6853.621556754461\n",
            "--------------------------\n",
            "iteration: 305\n",
            "cost: 6853.009521766691\n",
            "--------------------------\n",
            "iteration: 306\n",
            "cost: 6852.397641878767\n",
            "--------------------------\n",
            "iteration: 307\n",
            "cost: 6851.785917051394\n",
            "--------------------------\n",
            "iteration: 308\n",
            "cost: 6851.174347245277\n",
            "--------------------------\n",
            "iteration: 309\n",
            "cost: 6850.562932421121\n",
            "--------------------------\n",
            "iteration: 310\n",
            "cost: 6849.951672539659\n",
            "--------------------------\n",
            "iteration: 311\n",
            "cost: 6849.340567561636\n",
            "--------------------------\n",
            "iteration: 312\n",
            "cost: 6848.729617447774\n",
            "--------------------------\n",
            "iteration: 313\n",
            "cost: 6848.118822158845\n",
            "--------------------------\n",
            "iteration: 314\n",
            "cost: 6847.508181655609\n",
            "--------------------------\n",
            "iteration: 315\n",
            "cost: 6846.897695898844\n",
            "--------------------------\n",
            "iteration: 316\n",
            "cost: 6846.287364849328\n",
            "--------------------------\n",
            "iteration: 317\n",
            "cost: 6845.677188467858\n",
            "--------------------------\n",
            "iteration: 318\n",
            "cost: 6845.067166715236\n",
            "--------------------------\n",
            "iteration: 319\n",
            "cost: 6844.457299552285\n",
            "--------------------------\n",
            "iteration: 320\n",
            "cost: 6843.847586939822\n",
            "--------------------------\n",
            "iteration: 321\n",
            "cost: 6843.238028838687\n",
            "--------------------------\n",
            "iteration: 322\n",
            "cost: 6842.628625209717\n",
            "--------------------------\n",
            "iteration: 323\n",
            "cost: 6842.019376013768\n",
            "--------------------------\n",
            "iteration: 324\n",
            "cost: 6841.410281211707\n",
            "--------------------------\n",
            "iteration: 325\n",
            "cost: 6840.80134076441\n",
            "--------------------------\n",
            "iteration: 326\n",
            "cost: 6840.192554632762\n",
            "--------------------------\n",
            "iteration: 327\n",
            "cost: 6839.583922777645\n",
            "--------------------------\n",
            "iteration: 328\n",
            "cost: 6838.975445159973\n",
            "--------------------------\n",
            "iteration: 329\n",
            "cost: 6838.367121740659\n",
            "--------------------------\n",
            "iteration: 330\n",
            "cost: 6837.758952480626\n",
            "--------------------------\n",
            "iteration: 331\n",
            "cost: 6837.150937340802\n",
            "--------------------------\n",
            "iteration: 332\n",
            "cost: 6836.543076282137\n",
            "--------------------------\n",
            "iteration: 333\n",
            "cost: 6835.93536926558\n",
            "--------------------------\n",
            "iteration: 334\n",
            "cost: 6835.327816252099\n",
            "--------------------------\n",
            "iteration: 335\n",
            "cost: 6834.720417202666\n",
            "--------------------------\n",
            "iteration: 336\n",
            "cost: 6834.11317207826\n",
            "--------------------------\n",
            "iteration: 337\n",
            "cost: 6833.506080839873\n",
            "--------------------------\n",
            "iteration: 338\n",
            "cost: 6832.899143448517\n",
            "--------------------------\n",
            "iteration: 339\n",
            "cost: 6832.292359865192\n",
            "--------------------------\n",
            "iteration: 340\n",
            "cost: 6831.685730050927\n",
            "--------------------------\n",
            "iteration: 341\n",
            "cost: 6831.079253966762\n",
            "--------------------------\n",
            "iteration: 342\n",
            "cost: 6830.472931573723\n",
            "--------------------------\n",
            "iteration: 343\n",
            "cost: 6829.866762832867\n",
            "--------------------------\n",
            "iteration: 344\n",
            "cost: 6829.260747705271\n",
            "--------------------------\n",
            "iteration: 345\n",
            "cost: 6828.654886151991\n",
            "--------------------------\n",
            "iteration: 346\n",
            "cost: 6828.049178134112\n",
            "--------------------------\n",
            "iteration: 347\n",
            "cost: 6827.443623612725\n",
            "--------------------------\n",
            "iteration: 348\n",
            "cost: 6826.838222548935\n",
            "--------------------------\n",
            "iteration: 349\n",
            "cost: 6826.232974903849\n",
            "--------------------------\n",
            "iteration: 350\n",
            "cost: 6825.6278806385935\n",
            "--------------------------\n",
            "iteration: 351\n",
            "cost: 6825.022939714293\n",
            "--------------------------\n",
            "iteration: 352\n",
            "cost: 6824.418152092097\n",
            "--------------------------\n",
            "iteration: 353\n",
            "cost: 6823.813517733148\n",
            "--------------------------\n",
            "iteration: 354\n",
            "cost: 6823.2090365986105\n",
            "--------------------------\n",
            "iteration: 355\n",
            "cost: 6822.6047086496565\n",
            "--------------------------\n",
            "iteration: 356\n",
            "cost: 6822.000533847454\n",
            "--------------------------\n",
            "iteration: 357\n",
            "cost: 6821.396512153212\n",
            "--------------------------\n",
            "iteration: 358\n",
            "cost: 6820.792643528121\n",
            "--------------------------\n",
            "iteration: 359\n",
            "cost: 6820.188927933385\n",
            "--------------------------\n",
            "iteration: 360\n",
            "cost: 6819.585365330235\n",
            "--------------------------\n",
            "iteration: 361\n",
            "cost: 6818.981955679892\n",
            "--------------------------\n",
            "iteration: 362\n",
            "cost: 6818.378698943598\n",
            "--------------------------\n",
            "iteration: 363\n",
            "cost: 6817.7755950826\n",
            "--------------------------\n",
            "iteration: 364\n",
            "cost: 6817.172644058164\n",
            "--------------------------\n",
            "iteration: 365\n",
            "cost: 6816.569845831553\n",
            "--------------------------\n",
            "iteration: 366\n",
            "cost: 6815.967200364044\n",
            "--------------------------\n",
            "iteration: 367\n",
            "cost: 6815.364707616926\n",
            "--------------------------\n",
            "iteration: 368\n",
            "cost: 6814.762367551501\n",
            "--------------------------\n",
            "iteration: 369\n",
            "cost: 6814.160180129072\n",
            "--------------------------\n",
            "iteration: 370\n",
            "cost: 6813.558145310963\n",
            "--------------------------\n",
            "iteration: 371\n",
            "cost: 6812.956263058499\n",
            "--------------------------\n",
            "iteration: 372\n",
            "cost: 6812.354533333009\n",
            "--------------------------\n",
            "iteration: 373\n",
            "cost: 6811.752956095848\n",
            "--------------------------\n",
            "iteration: 374\n",
            "cost: 6811.151531308375\n",
            "--------------------------\n",
            "iteration: 375\n",
            "cost: 6810.550258931957\n",
            "--------------------------\n",
            "iteration: 376\n",
            "cost: 6809.94913892796\n",
            "--------------------------\n",
            "iteration: 377\n",
            "cost: 6809.348171257782\n",
            "--------------------------\n",
            "iteration: 378\n",
            "cost: 6808.747355882815\n",
            "--------------------------\n",
            "iteration: 379\n",
            "cost: 6808.14669276446\n",
            "--------------------------\n",
            "iteration: 380\n",
            "cost: 6807.546181864139\n",
            "--------------------------\n",
            "iteration: 381\n",
            "cost: 6806.945823143278\n",
            "--------------------------\n",
            "iteration: 382\n",
            "cost: 6806.345616563309\n",
            "--------------------------\n",
            "iteration: 383\n",
            "cost: 6805.745562085678\n",
            "--------------------------\n",
            "iteration: 384\n",
            "cost: 6805.145659671834\n",
            "--------------------------\n",
            "iteration: 385\n",
            "cost: 6804.545909283252\n",
            "--------------------------\n",
            "iteration: 386\n",
            "cost: 6803.946310881404\n",
            "--------------------------\n",
            "iteration: 387\n",
            "cost: 6803.34686442777\n",
            "--------------------------\n",
            "iteration: 388\n",
            "cost: 6802.747569883839\n",
            "--------------------------\n",
            "iteration: 389\n",
            "cost: 6802.148427211127\n",
            "--------------------------\n",
            "iteration: 390\n",
            "cost: 6801.549436371139\n",
            "--------------------------\n",
            "iteration: 391\n",
            "cost: 6800.950597325395\n",
            "--------------------------\n",
            "iteration: 392\n",
            "cost: 6800.351910035437\n",
            "--------------------------\n",
            "iteration: 393\n",
            "cost: 6799.753374462806\n",
            "--------------------------\n",
            "iteration: 394\n",
            "cost: 6799.154990569046\n",
            "--------------------------\n",
            "iteration: 395\n",
            "cost: 6798.55675831573\n",
            "--------------------------\n",
            "iteration: 396\n",
            "cost: 6797.958677664418\n",
            "--------------------------\n",
            "iteration: 397\n",
            "cost: 6797.360748576702\n",
            "--------------------------\n",
            "iteration: 398\n",
            "cost: 6796.762971014172\n",
            "--------------------------\n",
            "iteration: 399\n",
            "cost: 6796.165344938422\n",
            "--------------------------\n",
            "iteration: 400\n",
            "cost: 6795.56787031107\n",
            "--------------------------\n",
            "iteration: 401\n",
            "cost: 6794.970547093728\n",
            "--------------------------\n",
            "iteration: 402\n",
            "cost: 6794.37337524804\n",
            "--------------------------\n",
            "iteration: 403\n",
            "cost: 6793.776354735628\n",
            "--------------------------\n",
            "iteration: 404\n",
            "cost: 6793.179485518158\n",
            "--------------------------\n",
            "iteration: 405\n",
            "cost: 6792.582767557282\n",
            "--------------------------\n",
            "iteration: 406\n",
            "cost: 6791.986200814665\n",
            "--------------------------\n",
            "iteration: 407\n",
            "cost: 6791.389785251997\n",
            "--------------------------\n",
            "iteration: 408\n",
            "cost: 6790.793520830953\n",
            "--------------------------\n",
            "iteration: 409\n",
            "cost: 6790.197407513243\n",
            "--------------------------\n",
            "iteration: 410\n",
            "cost: 6789.601445260567\n",
            "--------------------------\n",
            "iteration: 411\n",
            "cost: 6789.005634034642\n",
            "--------------------------\n",
            "iteration: 412\n",
            "cost: 6788.409973797208\n",
            "--------------------------\n",
            "iteration: 413\n",
            "cost: 6787.814464509987\n",
            "--------------------------\n",
            "iteration: 414\n",
            "cost: 6787.219106134735\n",
            "--------------------------\n",
            "iteration: 415\n",
            "cost: 6786.623898633197\n",
            "--------------------------\n",
            "iteration: 416\n",
            "cost: 6786.028841967153\n",
            "--------------------------\n",
            "iteration: 417\n",
            "cost: 6785.433936098374\n",
            "--------------------------\n",
            "iteration: 418\n",
            "cost: 6784.839180988643\n",
            "--------------------------\n",
            "iteration: 419\n",
            "cost: 6784.244576599756\n",
            "--------------------------\n",
            "iteration: 420\n",
            "cost: 6783.650122893514\n",
            "--------------------------\n",
            "iteration: 421\n",
            "cost: 6783.05581983174\n",
            "--------------------------\n",
            "iteration: 422\n",
            "cost: 6782.4616673762575\n",
            "--------------------------\n",
            "iteration: 423\n",
            "cost: 6781.867665488893\n",
            "--------------------------\n",
            "iteration: 424\n",
            "cost: 6781.273814131491\n",
            "--------------------------\n",
            "iteration: 425\n",
            "cost: 6780.6801132659075\n",
            "--------------------------\n",
            "iteration: 426\n",
            "cost: 6780.086562854012\n",
            "--------------------------\n",
            "iteration: 427\n",
            "cost: 6779.493162857665\n",
            "--------------------------\n",
            "iteration: 428\n",
            "cost: 6778.899913238757\n",
            "--------------------------\n",
            "iteration: 429\n",
            "cost: 6778.306813959173\n",
            "--------------------------\n",
            "iteration: 430\n",
            "cost: 6777.713864980823\n",
            "--------------------------\n",
            "iteration: 431\n",
            "cost: 6777.12106626561\n",
            "--------------------------\n",
            "iteration: 432\n",
            "cost: 6776.528417775463\n",
            "--------------------------\n",
            "iteration: 433\n",
            "cost: 6775.935919472302\n",
            "--------------------------\n",
            "iteration: 434\n",
            "cost: 6775.343571318078\n",
            "--------------------------\n",
            "iteration: 435\n",
            "cost: 6774.751373274732\n",
            "--------------------------\n",
            "iteration: 436\n",
            "cost: 6774.15932530423\n",
            "--------------------------\n",
            "iteration: 437\n",
            "cost: 6773.567427368536\n",
            "--------------------------\n",
            "iteration: 438\n",
            "cost: 6772.975679429634\n",
            "--------------------------\n",
            "iteration: 439\n",
            "cost: 6772.384081449503\n",
            "--------------------------\n",
            "iteration: 440\n",
            "cost: 6771.792633390153\n",
            "--------------------------\n",
            "iteration: 441\n",
            "cost: 6771.201335213586\n",
            "--------------------------\n",
            "iteration: 442\n",
            "cost: 6770.610186881818\n",
            "--------------------------\n",
            "iteration: 443\n",
            "cost: 6770.019188356877\n",
            "--------------------------\n",
            "iteration: 444\n",
            "cost: 6769.428339600798\n",
            "--------------------------\n",
            "iteration: 445\n",
            "cost: 6768.837640575626\n",
            "--------------------------\n",
            "iteration: 446\n",
            "cost: 6768.24709124342\n",
            "--------------------------\n",
            "iteration: 447\n",
            "cost: 6767.65669156625\n",
            "--------------------------\n",
            "iteration: 448\n",
            "cost: 6767.066441506179\n",
            "--------------------------\n",
            "iteration: 449\n",
            "cost: 6766.476341025303\n",
            "--------------------------\n",
            "iteration: 450\n",
            "cost: 6765.886390085705\n",
            "--------------------------\n",
            "iteration: 451\n",
            "cost: 6765.2965886494985\n",
            "--------------------------\n",
            "iteration: 452\n",
            "cost: 6764.706936678796\n",
            "--------------------------\n",
            "iteration: 453\n",
            "cost: 6764.117434135708\n",
            "--------------------------\n",
            "iteration: 454\n",
            "cost: 6763.528080982386\n",
            "--------------------------\n",
            "iteration: 455\n",
            "cost: 6762.938877180961\n",
            "--------------------------\n",
            "iteration: 456\n",
            "cost: 6762.349822693583\n",
            "--------------------------\n",
            "iteration: 457\n",
            "cost: 6761.760917482417\n",
            "--------------------------\n",
            "iteration: 458\n",
            "cost: 6761.172161509637\n",
            "--------------------------\n",
            "iteration: 459\n",
            "cost: 6760.583554737417\n",
            "--------------------------\n",
            "iteration: 460\n",
            "cost: 6759.995097127952\n",
            "--------------------------\n",
            "iteration: 461\n",
            "cost: 6759.4067886434395\n",
            "--------------------------\n",
            "iteration: 462\n",
            "cost: 6758.818629246089\n",
            "--------------------------\n",
            "iteration: 463\n",
            "cost: 6758.230618898119\n",
            "--------------------------\n",
            "iteration: 464\n",
            "cost: 6757.642757561762\n",
            "--------------------------\n",
            "iteration: 465\n",
            "cost: 6757.055045199244\n",
            "--------------------------\n",
            "iteration: 466\n",
            "cost: 6756.467481772833\n",
            "--------------------------\n",
            "iteration: 467\n",
            "cost: 6755.880067244766\n",
            "--------------------------\n",
            "iteration: 468\n",
            "cost: 6755.292801577323\n",
            "--------------------------\n",
            "iteration: 469\n",
            "cost: 6754.705684732769\n",
            "--------------------------\n",
            "iteration: 470\n",
            "cost: 6754.118716673402\n",
            "--------------------------\n",
            "iteration: 471\n",
            "cost: 6753.531897361501\n",
            "--------------------------\n",
            "iteration: 472\n",
            "cost: 6752.945226759393\n",
            "--------------------------\n",
            "iteration: 473\n",
            "cost: 6752.358704829373\n",
            "--------------------------\n",
            "iteration: 474\n",
            "cost: 6751.772331533777\n",
            "--------------------------\n",
            "iteration: 475\n",
            "cost: 6751.186106834932\n",
            "--------------------------\n",
            "iteration: 476\n",
            "cost: 6750.6000306951855\n",
            "--------------------------\n",
            "iteration: 477\n",
            "cost: 6750.014103076882\n",
            "--------------------------\n",
            "iteration: 478\n",
            "cost: 6749.428323942395\n",
            "--------------------------\n",
            "iteration: 479\n",
            "cost: 6748.842693254087\n",
            "--------------------------\n",
            "iteration: 480\n",
            "cost: 6748.2572109743505\n",
            "--------------------------\n",
            "iteration: 481\n",
            "cost: 6747.6718770655625\n",
            "--------------------------\n",
            "iteration: 482\n",
            "cost: 6747.086691490134\n",
            "--------------------------\n",
            "iteration: 483\n",
            "cost: 6746.501654210467\n",
            "--------------------------\n",
            "iteration: 484\n",
            "cost: 6745.916765188982\n",
            "--------------------------\n",
            "iteration: 485\n",
            "cost: 6745.332024388113\n",
            "--------------------------\n",
            "iteration: 486\n",
            "cost: 6744.747431770302\n",
            "--------------------------\n",
            "iteration: 487\n",
            "cost: 6744.1629872979875\n",
            "--------------------------\n",
            "iteration: 488\n",
            "cost: 6743.578690933621\n",
            "--------------------------\n",
            "iteration: 489\n",
            "cost: 6742.99454263969\n",
            "--------------------------\n",
            "iteration: 490\n",
            "cost: 6742.410542378651\n",
            "--------------------------\n",
            "iteration: 491\n",
            "cost: 6741.826690113003\n",
            "--------------------------\n",
            "iteration: 492\n",
            "cost: 6741.242985805242\n",
            "--------------------------\n",
            "iteration: 493\n",
            "cost: 6740.659429417865\n",
            "--------------------------\n",
            "iteration: 494\n",
            "cost: 6740.076020913388\n",
            "--------------------------\n",
            "iteration: 495\n",
            "cost: 6739.492760254337\n",
            "--------------------------\n",
            "iteration: 496\n",
            "cost: 6738.909647403246\n",
            "--------------------------\n",
            "iteration: 497\n",
            "cost: 6738.326682322656\n",
            "--------------------------\n",
            "iteration: 498\n",
            "cost: 6737.74386497512\n",
            "--------------------------\n",
            "iteration: 499\n",
            "cost: 6737.161195323204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j2PWxLQ_RFO"
      },
      "source": [
        "### Stochastic Gradient Descent\n",
        "Algorithm can be given as follows:\n",
        "```shuffle(x, y)\n",
        "for i in 0 -> m:\n",
        "    theta += (alpha / m) * (y[i] - h(x[i])) * x_bar  \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLDS-LYG_RFP"
      },
      "source": [
        "def linear_regression_using_stochastic_gradient_descent(ip, op, params, alpha):\n",
        "    \"\"\"\n",
        "    Compute the params for linear regression using stochastic gradient descent\n",
        "    ip: input variables\n",
        "    op: output variables\n",
        "    params: corresponding parameters\n",
        "    alpha: learning rate\n",
        "    Returns parameters, cost, params_store\n",
        "    \"\"\"\n",
        "    # Start code here\n",
        "    # initialize iteration, number of samples, cost and parameter array\n",
        "    iteration = 0\n",
        "    max_iter = 5000\n",
        "    num_samples = len(op)\n",
        "    cost = []\n",
        "    params_store = np.zeros((2, max_iter))\n",
        "    \n",
        "    # Compute the cost and store the params for the corresponding cost\n",
        "    while iteration < max_iter:\n",
        "        cost.append(compute_cost(ip, op, params))\n",
        "        params_store[:, iteration] = params\n",
        "\n",
        "        print('--------------------------')\n",
        "        print(f'iteration: {iteration}')\n",
        "        print(f'cost: {cost[iteration]}')\n",
        "\n",
        "        i = np.random.randint(num_samples)\n",
        "\n",
        "        #for x, y in zip(ip, op):\n",
        "        y_hat = params[0] + params[1] * ip[i]\n",
        "        gradient_0 = (y_hat - op[i]) / num_samples / 2\n",
        "        gradient_1 = (y_hat - op[i]) * ip[i] / num_samples / 2\n",
        "\n",
        "        params[0] = params[0] - alpha * gradient_0\n",
        "        params[1] = params[1] - alpha * gradient_1\n",
        "        \n",
        "        if (abs(cost[iteration] - compute_cost(ip, op, params)) < 0.001):\n",
        "            break  \n",
        "        iteration += 1  \n",
        "    return params, cost, params_store"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evnjXWrv_RFP",
        "outputId": "1ee9d3ed-bbc9-4ff4-dc11-e05bd8a5ae34"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "alpha = 1e-3\n",
        "params_0 = np.array([20.0, 80.0])\n",
        "params_hat, cost, params_store =\\\n",
        "linear_regression_using_stochastic_gradient_descent(x_train, y_train, params_0, alpha)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------\n",
            "iteration: 0\n",
            "cost: 6574048.46460789\n",
            "--------------------------\n",
            "iteration: 1\n",
            "cost: 6190969.073962705\n",
            "--------------------------\n",
            "iteration: 2\n",
            "cost: 5574386.474943316\n",
            "--------------------------\n",
            "iteration: 3\n",
            "cost: 4911624.772433495\n",
            "--------------------------\n",
            "iteration: 4\n",
            "cost: 4855384.815819754\n",
            "--------------------------\n",
            "iteration: 5\n",
            "cost: 4564135.2668009605\n",
            "--------------------------\n",
            "iteration: 6\n",
            "cost: 4117415.216504437\n",
            "--------------------------\n",
            "iteration: 7\n",
            "cost: 3946124.6727462024\n",
            "--------------------------\n",
            "iteration: 8\n",
            "cost: 3937579.0184582574\n",
            "--------------------------\n",
            "iteration: 9\n",
            "cost: 3751153.576722525\n",
            "--------------------------\n",
            "iteration: 10\n",
            "cost: 3637157.0087249456\n",
            "--------------------------\n",
            "iteration: 11\n",
            "cost: 3589333.5337317204\n",
            "--------------------------\n",
            "iteration: 12\n",
            "cost: 3544546.015146536\n",
            "--------------------------\n",
            "iteration: 13\n",
            "cost: 3500306.9897522912\n",
            "--------------------------\n",
            "iteration: 14\n",
            "cost: 3499145.5001646294\n",
            "--------------------------\n",
            "iteration: 15\n",
            "cost: 3113530.091546003\n",
            "--------------------------\n",
            "iteration: 16\n",
            "cost: 3091949.0472569345\n",
            "--------------------------\n",
            "iteration: 17\n",
            "cost: 2795735.544977768\n",
            "--------------------------\n",
            "iteration: 18\n",
            "cost: 2504015.5821644613\n",
            "--------------------------\n",
            "iteration: 19\n",
            "cost: 2471998.9525398226\n",
            "--------------------------\n",
            "iteration: 20\n",
            "cost: 2439736.6015906446\n",
            "--------------------------\n",
            "iteration: 21\n",
            "cost: 2439650.619439152\n",
            "--------------------------\n",
            "iteration: 22\n",
            "cost: 2411511.4869571785\n",
            "--------------------------\n",
            "iteration: 23\n",
            "cost: 2406318.041430372\n",
            "--------------------------\n",
            "iteration: 24\n",
            "cost: 2224386.85282265\n",
            "--------------------------\n",
            "iteration: 25\n",
            "cost: 2068932.8325823364\n",
            "--------------------------\n",
            "iteration: 26\n",
            "cost: 1922836.415216005\n",
            "--------------------------\n",
            "iteration: 27\n",
            "cost: 1905814.9587316357\n",
            "--------------------------\n",
            "iteration: 28\n",
            "cost: 1864741.0641976383\n",
            "--------------------------\n",
            "iteration: 29\n",
            "cost: 1811766.7475967866\n",
            "--------------------------\n",
            "iteration: 30\n",
            "cost: 1788490.8935371633\n",
            "--------------------------\n",
            "iteration: 31\n",
            "cost: 1786253.8853353295\n",
            "--------------------------\n",
            "iteration: 32\n",
            "cost: 1575934.2447678666\n",
            "--------------------------\n",
            "iteration: 33\n",
            "cost: 1516271.1458670252\n",
            "--------------------------\n",
            "iteration: 34\n",
            "cost: 1483873.2534450279\n",
            "--------------------------\n",
            "iteration: 35\n",
            "cost: 1425748.0685975684\n",
            "--------------------------\n",
            "iteration: 36\n",
            "cost: 1287079.9211543843\n",
            "--------------------------\n",
            "iteration: 37\n",
            "cost: 1287407.2725171722\n",
            "--------------------------\n",
            "iteration: 38\n",
            "cost: 1226732.5270864894\n",
            "--------------------------\n",
            "iteration: 39\n",
            "cost: 1103580.435849846\n",
            "--------------------------\n",
            "iteration: 40\n",
            "cost: 1019556.030244664\n",
            "--------------------------\n",
            "iteration: 41\n",
            "cost: 1019271.6168400936\n",
            "--------------------------\n",
            "iteration: 42\n",
            "cost: 990438.3245217176\n",
            "--------------------------\n",
            "iteration: 43\n",
            "cost: 974159.8292423993\n",
            "--------------------------\n",
            "iteration: 44\n",
            "cost: 936879.1940357294\n",
            "--------------------------\n",
            "iteration: 45\n",
            "cost: 931080.0201398355\n",
            "--------------------------\n",
            "iteration: 46\n",
            "cost: 931432.1004995306\n",
            "--------------------------\n",
            "iteration: 47\n",
            "cost: 928498.61390795\n",
            "--------------------------\n",
            "iteration: 48\n",
            "cost: 884847.9616001487\n",
            "--------------------------\n",
            "iteration: 49\n",
            "cost: 859851.5130272737\n",
            "--------------------------\n",
            "iteration: 50\n",
            "cost: 797740.7441000987\n",
            "--------------------------\n",
            "iteration: 51\n",
            "cost: 787249.3672192686\n",
            "--------------------------\n",
            "iteration: 52\n",
            "cost: 696624.4052789671\n",
            "--------------------------\n",
            "iteration: 53\n",
            "cost: 688884.8481126797\n",
            "--------------------------\n",
            "iteration: 54\n",
            "cost: 662286.4275022661\n",
            "--------------------------\n",
            "iteration: 55\n",
            "cost: 614149.8366131643\n",
            "--------------------------\n",
            "iteration: 56\n",
            "cost: 538387.8678808839\n",
            "--------------------------\n",
            "iteration: 57\n",
            "cost: 497541.377078289\n",
            "--------------------------\n",
            "iteration: 58\n",
            "cost: 467322.6372402272\n",
            "--------------------------\n",
            "iteration: 59\n",
            "cost: 467154.8603600032\n",
            "--------------------------\n",
            "iteration: 60\n",
            "cost: 465331.61995279277\n",
            "--------------------------\n",
            "iteration: 61\n",
            "cost: 454303.84480509267\n",
            "--------------------------\n",
            "iteration: 62\n",
            "cost: 453469.07646420394\n",
            "--------------------------\n",
            "iteration: 63\n",
            "cost: 435751.18956080184\n",
            "--------------------------\n",
            "iteration: 64\n",
            "cost: 435775.7655089055\n",
            "--------------------------\n",
            "iteration: 65\n",
            "cost: 404781.53792112\n",
            "--------------------------\n",
            "iteration: 66\n",
            "cost: 393480.2034493593\n",
            "--------------------------\n",
            "iteration: 67\n",
            "cost: 387338.69605048624\n",
            "--------------------------\n",
            "iteration: 68\n",
            "cost: 356683.7896190852\n",
            "--------------------------\n",
            "iteration: 69\n",
            "cost: 313581.3579759371\n",
            "--------------------------\n",
            "iteration: 70\n",
            "cost: 280801.69588719535\n",
            "--------------------------\n",
            "iteration: 71\n",
            "cost: 281109.79129825364\n",
            "--------------------------\n",
            "iteration: 72\n",
            "cost: 248219.53374410342\n",
            "--------------------------\n",
            "iteration: 73\n",
            "cost: 218546.85227598454\n",
            "--------------------------\n",
            "iteration: 74\n",
            "cost: 218819.5712585093\n",
            "--------------------------\n",
            "iteration: 75\n",
            "cost: 212202.64849147535\n",
            "--------------------------\n",
            "iteration: 76\n",
            "cost: 186342.33587118596\n",
            "--------------------------\n",
            "iteration: 77\n",
            "cost: 162717.4050647313\n",
            "--------------------------\n",
            "iteration: 78\n",
            "cost: 149322.27942773278\n",
            "--------------------------\n",
            "iteration: 79\n",
            "cost: 133778.75883552423\n",
            "--------------------------\n",
            "iteration: 80\n",
            "cost: 133425.97610770684\n",
            "--------------------------\n",
            "iteration: 81\n",
            "cost: 119489.68696940476\n",
            "--------------------------\n",
            "iteration: 82\n",
            "cost: 119442.90449693907\n",
            "--------------------------\n",
            "iteration: 83\n",
            "cost: 115788.41586248993\n",
            "--------------------------\n",
            "iteration: 84\n",
            "cost: 112797.00322211286\n",
            "--------------------------\n",
            "iteration: 85\n",
            "cost: 108203.67045490004\n",
            "--------------------------\n",
            "iteration: 86\n",
            "cost: 107392.15538751411\n",
            "--------------------------\n",
            "iteration: 87\n",
            "cost: 102905.39159240767\n",
            "--------------------------\n",
            "iteration: 88\n",
            "cost: 102844.61438218484\n",
            "--------------------------\n",
            "iteration: 89\n",
            "cost: 101221.98499700634\n",
            "--------------------------\n",
            "iteration: 90\n",
            "cost: 92713.21319009864\n",
            "--------------------------\n",
            "iteration: 91\n",
            "cost: 88740.17253245506\n",
            "--------------------------\n",
            "iteration: 92\n",
            "cost: 88535.06603105934\n",
            "--------------------------\n",
            "iteration: 93\n",
            "cost: 88615.22896191315\n",
            "--------------------------\n",
            "iteration: 94\n",
            "cost: 87538.13222793388\n",
            "--------------------------\n",
            "iteration: 95\n",
            "cost: 83042.06791834402\n",
            "--------------------------\n",
            "iteration: 96\n",
            "cost: 81003.84943155458\n",
            "--------------------------\n",
            "iteration: 97\n",
            "cost: 73019.03581829439\n",
            "--------------------------\n",
            "iteration: 98\n",
            "cost: 71977.04489073747\n",
            "--------------------------\n",
            "iteration: 99\n",
            "cost: 65854.24766291244\n",
            "--------------------------\n",
            "iteration: 100\n",
            "cost: 58882.68277439506\n",
            "--------------------------\n",
            "iteration: 101\n",
            "cost: 58822.73451200415\n",
            "--------------------------\n",
            "iteration: 102\n",
            "cost: 58757.01600946787\n",
            "--------------------------\n",
            "iteration: 103\n",
            "cost: 58778.87801720251\n",
            "--------------------------\n",
            "iteration: 104\n",
            "cost: 51285.41233406669\n",
            "--------------------------\n",
            "iteration: 105\n",
            "cost: 46839.63923926003\n",
            "--------------------------\n",
            "iteration: 106\n",
            "cost: 45823.026830863164\n",
            "--------------------------\n",
            "iteration: 107\n",
            "cost: 45838.83062754474\n",
            "--------------------------\n",
            "iteration: 108\n",
            "cost: 45841.0622500281\n",
            "--------------------------\n",
            "iteration: 109\n",
            "cost: 45981.33211217706\n",
            "--------------------------\n",
            "iteration: 110\n",
            "cost: 44422.106135573544\n",
            "--------------------------\n",
            "iteration: 111\n",
            "cost: 44403.76196657038\n",
            "--------------------------\n",
            "iteration: 112\n",
            "cost: 44613.47390644004\n",
            "--------------------------\n",
            "iteration: 113\n",
            "cost: 40914.42661286258\n",
            "--------------------------\n",
            "iteration: 114\n",
            "cost: 41126.41993959168\n",
            "--------------------------\n",
            "iteration: 115\n",
            "cost: 36958.901661723125\n",
            "--------------------------\n",
            "iteration: 116\n",
            "cost: 35563.42767252967\n",
            "--------------------------\n",
            "iteration: 117\n",
            "cost: 34107.96212497841\n",
            "--------------------------\n",
            "iteration: 118\n",
            "cost: 32661.295489666576\n",
            "--------------------------\n",
            "iteration: 119\n",
            "cost: 32647.78318907913\n",
            "--------------------------\n",
            "iteration: 120\n",
            "cost: 30223.66605911473\n",
            "--------------------------\n",
            "iteration: 121\n",
            "cost: 28950.020524485113\n",
            "--------------------------\n",
            "iteration: 122\n",
            "cost: 27925.958371423145\n",
            "--------------------------\n",
            "iteration: 123\n",
            "cost: 26615.073241160462\n",
            "--------------------------\n",
            "iteration: 124\n",
            "cost: 26493.81296732036\n",
            "--------------------------\n",
            "iteration: 125\n",
            "cost: 25937.7333759802\n",
            "--------------------------\n",
            "iteration: 126\n",
            "cost: 26013.83628041413\n",
            "--------------------------\n",
            "iteration: 127\n",
            "cost: 26089.125614842855\n",
            "--------------------------\n",
            "iteration: 128\n",
            "cost: 25595.687493864745\n",
            "--------------------------\n",
            "iteration: 129\n",
            "cost: 25313.474552270123\n",
            "--------------------------\n",
            "iteration: 130\n",
            "cost: 24962.407157784903\n",
            "--------------------------\n",
            "iteration: 131\n",
            "cost: 22902.826159090124\n",
            "--------------------------\n",
            "iteration: 132\n",
            "cost: 20245.684575252242\n",
            "--------------------------\n",
            "iteration: 133\n",
            "cost: 20000.38207906446\n",
            "--------------------------\n",
            "iteration: 134\n",
            "cost: 20015.776391333595\n",
            "--------------------------\n",
            "iteration: 135\n",
            "cost: 17761.504766203772\n",
            "--------------------------\n",
            "iteration: 136\n",
            "cost: 17615.808557668483\n",
            "--------------------------\n",
            "iteration: 137\n",
            "cost: 17829.91146744235\n",
            "--------------------------\n",
            "iteration: 138\n",
            "cost: 17979.78867754447\n",
            "--------------------------\n",
            "iteration: 139\n",
            "cost: 17823.18009083822\n",
            "--------------------------\n",
            "iteration: 140\n",
            "cost: 16572.967017743482\n",
            "--------------------------\n",
            "iteration: 141\n",
            "cost: 16594.095082533626\n",
            "--------------------------\n",
            "iteration: 142\n",
            "cost: 16266.01822386863\n",
            "--------------------------\n",
            "iteration: 143\n",
            "cost: 16297.522781426936\n",
            "--------------------------\n",
            "iteration: 144\n",
            "cost: 14729.790443969532\n",
            "--------------------------\n",
            "iteration: 145\n",
            "cost: 14850.70266933274\n",
            "--------------------------\n",
            "iteration: 146\n",
            "cost: 13494.881187182244\n",
            "--------------------------\n",
            "iteration: 147\n",
            "cost: 13648.168730855818\n",
            "--------------------------\n",
            "iteration: 148\n",
            "cost: 13554.450137916583\n",
            "--------------------------\n",
            "iteration: 149\n",
            "cost: 12383.644934948612\n",
            "--------------------------\n",
            "iteration: 150\n",
            "cost: 11576.527394794979\n",
            "--------------------------\n",
            "iteration: 151\n",
            "cost: 11577.398192263077\n",
            "--------------------------\n",
            "iteration: 152\n",
            "cost: 11385.032300529794\n",
            "--------------------------\n",
            "iteration: 153\n",
            "cost: 10541.851185180634\n",
            "--------------------------\n",
            "iteration: 154\n",
            "cost: 10612.391369590381\n",
            "--------------------------\n",
            "iteration: 155\n",
            "cost: 9890.641636229415\n",
            "--------------------------\n",
            "iteration: 156\n",
            "cost: 9891.34001898481\n",
            "--------------------------\n",
            "iteration: 157\n",
            "cost: 9761.967753857989\n",
            "--------------------------\n",
            "iteration: 158\n",
            "cost: 9266.328096275334\n",
            "--------------------------\n",
            "iteration: 159\n",
            "cost: 9294.238749038619\n",
            "--------------------------\n",
            "iteration: 160\n",
            "cost: 9241.94602162537\n",
            "--------------------------\n",
            "iteration: 161\n",
            "cost: 9328.680360767217\n",
            "--------------------------\n",
            "iteration: 162\n",
            "cost: 9280.060183945887\n",
            "--------------------------\n",
            "iteration: 163\n",
            "cost: 9247.466844209854\n",
            "--------------------------\n",
            "iteration: 164\n",
            "cost: 9334.292061772298\n",
            "--------------------------\n",
            "iteration: 165\n",
            "cost: 9300.956918283697\n",
            "--------------------------\n",
            "iteration: 166\n",
            "cost: 9314.88846825854\n",
            "--------------------------\n",
            "iteration: 167\n",
            "cost: 9354.465617927339\n",
            "--------------------------\n",
            "iteration: 168\n",
            "cost: 9225.742332475475\n",
            "--------------------------\n",
            "iteration: 169\n",
            "cost: 9178.660964977356\n",
            "--------------------------\n",
            "iteration: 170\n",
            "cost: 9247.11487554197\n",
            "--------------------------\n",
            "iteration: 171\n",
            "cost: 9378.48938949996\n",
            "--------------------------\n",
            "iteration: 172\n",
            "cost: 9080.648930527263\n",
            "--------------------------\n",
            "iteration: 173\n",
            "cost: 9146.608145228925\n",
            "--------------------------\n",
            "iteration: 174\n",
            "cost: 8584.110603129611\n",
            "--------------------------\n",
            "iteration: 175\n",
            "cost: 8593.337061564442\n",
            "--------------------------\n",
            "iteration: 176\n",
            "cost: 8655.90157598352\n",
            "--------------------------\n",
            "iteration: 177\n",
            "cost: 8190.073349808867\n",
            "--------------------------\n",
            "iteration: 178\n",
            "cost: 8200.319386518784\n",
            "--------------------------\n",
            "iteration: 179\n",
            "cost: 8310.697627118094\n",
            "--------------------------\n",
            "iteration: 180\n",
            "cost: 8017.160419060948\n",
            "--------------------------\n",
            "iteration: 181\n",
            "cost: 7934.983660627261\n",
            "--------------------------\n",
            "iteration: 182\n",
            "cost: 7989.406597904233\n",
            "--------------------------\n",
            "iteration: 183\n",
            "cost: 7947.799948137865\n",
            "--------------------------\n",
            "iteration: 184\n",
            "cost: 7972.2084106684\n",
            "--------------------------\n",
            "iteration: 185\n",
            "cost: 7867.650363974225\n",
            "--------------------------\n",
            "iteration: 186\n",
            "cost: 7912.011227880934\n",
            "--------------------------\n",
            "iteration: 187\n",
            "cost: 7906.574614276689\n",
            "--------------------------\n",
            "iteration: 188\n",
            "cost: 7932.344109835196\n",
            "--------------------------\n",
            "iteration: 189\n",
            "cost: 7708.8132460002425\n",
            "--------------------------\n",
            "iteration: 190\n",
            "cost: 7516.765264736228\n",
            "--------------------------\n",
            "iteration: 191\n",
            "cost: 7516.752769957178\n",
            "--------------------------\n",
            "iteration: 192\n",
            "cost: 7488.830093289046\n",
            "--------------------------\n",
            "iteration: 193\n",
            "cost: 7327.86086176867\n",
            "--------------------------\n",
            "iteration: 194\n",
            "cost: 7362.780194602626\n",
            "--------------------------\n",
            "iteration: 195\n",
            "cost: 7221.462859798655\n",
            "--------------------------\n",
            "iteration: 196\n",
            "cost: 7221.63946865161\n",
            "--------------------------\n",
            "iteration: 197\n",
            "cost: 7221.613832692579\n",
            "--------------------------\n",
            "iteration: 198\n",
            "cost: 7254.427049827778\n",
            "--------------------------\n",
            "iteration: 199\n",
            "cost: 7191.719401322394\n",
            "--------------------------\n",
            "iteration: 200\n",
            "cost: 7240.449547635406\n",
            "--------------------------\n",
            "iteration: 201\n",
            "cost: 7267.058156738982\n",
            "--------------------------\n",
            "iteration: 202\n",
            "cost: 7291.965893963066\n",
            "--------------------------\n",
            "iteration: 203\n",
            "cost: 7300.450365804919\n",
            "--------------------------\n",
            "iteration: 204\n",
            "cost: 7323.2030166077675\n",
            "--------------------------\n",
            "iteration: 205\n",
            "cost: 7324.4251983658905\n",
            "--------------------------\n",
            "iteration: 206\n",
            "cost: 7352.708622244172\n",
            "--------------------------\n",
            "iteration: 207\n",
            "cost: 7290.285393585031\n",
            "--------------------------\n",
            "iteration: 208\n",
            "cost: 7328.042722007858\n",
            "--------------------------\n",
            "iteration: 209\n",
            "cost: 7353.917081523922\n",
            "--------------------------\n",
            "iteration: 210\n",
            "cost: 7396.63081569769\n",
            "--------------------------\n",
            "iteration: 211\n",
            "cost: 7374.259489836416\n",
            "--------------------------\n",
            "iteration: 212\n",
            "cost: 7416.997602394023\n",
            "--------------------------\n",
            "iteration: 213\n",
            "cost: 7423.634662455412\n",
            "--------------------------\n",
            "iteration: 214\n",
            "cost: 7366.02641529206\n",
            "--------------------------\n",
            "iteration: 215\n",
            "cost: 7381.343721204973\n",
            "--------------------------\n",
            "iteration: 216\n",
            "cost: 7383.532502070996\n",
            "--------------------------\n",
            "iteration: 217\n",
            "cost: 7273.282141613674\n",
            "--------------------------\n",
            "iteration: 218\n",
            "cost: 7296.597649643598\n",
            "--------------------------\n",
            "iteration: 219\n",
            "cost: 7321.404380678531\n",
            "--------------------------\n",
            "iteration: 220\n",
            "cost: 7328.215129299702\n",
            "--------------------------\n",
            "iteration: 221\n",
            "cost: 7334.54558756396\n",
            "--------------------------\n",
            "iteration: 222\n",
            "cost: 7362.275596911566\n",
            "--------------------------\n",
            "iteration: 223\n",
            "cost: 7233.815436195282\n",
            "--------------------------\n",
            "iteration: 224\n",
            "cost: 7233.524469277116\n",
            "--------------------------\n",
            "iteration: 225\n",
            "cost: 7240.139802073516\n",
            "--------------------------\n",
            "iteration: 226\n",
            "cost: 7249.12392776977\n",
            "--------------------------\n",
            "iteration: 227\n",
            "cost: 7249.09986994343\n",
            "--------------------------\n",
            "iteration: 228\n",
            "cost: 7269.707223449064\n",
            "--------------------------\n",
            "iteration: 229\n",
            "cost: 7184.508835892392\n",
            "--------------------------\n",
            "iteration: 230\n",
            "cost: 7194.196337405631\n",
            "--------------------------\n",
            "iteration: 231\n",
            "cost: 7195.661897311916\n",
            "--------------------------\n",
            "iteration: 232\n",
            "cost: 7195.634713240895\n",
            "--------------------------\n",
            "iteration: 233\n",
            "cost: 7219.216885848556\n",
            "--------------------------\n",
            "iteration: 234\n",
            "cost: 7218.711177247003\n",
            "--------------------------\n",
            "iteration: 235\n",
            "cost: 7199.150453325099\n",
            "--------------------------\n",
            "iteration: 236\n",
            "cost: 7248.256147318641\n",
            "--------------------------\n",
            "iteration: 237\n",
            "cost: 7253.666299882605\n",
            "--------------------------\n",
            "iteration: 238\n",
            "cost: 7229.629056867979\n",
            "--------------------------\n",
            "iteration: 239\n",
            "cost: 7207.380551093345\n",
            "--------------------------\n",
            "iteration: 240\n",
            "cost: 7164.708806965062\n",
            "--------------------------\n",
            "iteration: 241\n",
            "cost: 7206.927285369755\n",
            "--------------------------\n",
            "iteration: 242\n",
            "cost: 7233.159112399686\n",
            "--------------------------\n",
            "iteration: 243\n",
            "cost: 7212.4040162775755\n",
            "--------------------------\n",
            "iteration: 244\n",
            "cost: 7234.802745168001\n",
            "--------------------------\n",
            "iteration: 245\n",
            "cost: 7242.9137675435195\n",
            "--------------------------\n",
            "iteration: 246\n",
            "cost: 7139.777554056137\n",
            "--------------------------\n",
            "iteration: 247\n",
            "cost: 7147.120881654386\n",
            "--------------------------\n",
            "iteration: 248\n",
            "cost: 7154.603404427701\n",
            "--------------------------\n",
            "iteration: 249\n",
            "cost: 7148.286622949187\n",
            "--------------------------\n",
            "iteration: 250\n",
            "cost: 7149.509248858219\n",
            "--------------------------\n",
            "iteration: 251\n",
            "cost: 7149.126655856225\n",
            "--------------------------\n",
            "iteration: 252\n",
            "cost: 7104.353502965352\n",
            "--------------------------\n",
            "iteration: 253\n",
            "cost: 7119.67817435773\n",
            "--------------------------\n",
            "iteration: 254\n",
            "cost: 7087.872042908952\n",
            "--------------------------\n",
            "iteration: 255\n",
            "cost: 7105.492041548314\n",
            "--------------------------\n",
            "iteration: 256\n",
            "cost: 7058.981829719276\n",
            "--------------------------\n",
            "iteration: 257\n",
            "cost: 7062.875839863822\n",
            "--------------------------\n",
            "iteration: 258\n",
            "cost: 7082.9689505056685\n",
            "--------------------------\n",
            "iteration: 259\n",
            "cost: 7096.170871278331\n",
            "--------------------------\n",
            "iteration: 260\n",
            "cost: 7056.137877414997\n",
            "--------------------------\n",
            "iteration: 261\n",
            "cost: 7053.286545294513\n",
            "--------------------------\n",
            "iteration: 262\n",
            "cost: 7050.820173203252\n",
            "--------------------------\n",
            "iteration: 263\n",
            "cost: 7067.039155776758\n",
            "--------------------------\n",
            "iteration: 264\n",
            "cost: 7083.2742350616945\n",
            "--------------------------\n",
            "iteration: 265\n",
            "cost: 7092.292269436191\n",
            "--------------------------\n",
            "iteration: 266\n",
            "cost: 7060.227850011955\n",
            "--------------------------\n",
            "iteration: 267\n",
            "cost: 7074.70129055597\n",
            "--------------------------\n",
            "iteration: 268\n",
            "cost: 7079.268733516871\n",
            "--------------------------\n",
            "iteration: 269\n",
            "cost: 7095.290581929366\n",
            "--------------------------\n",
            "iteration: 270\n",
            "cost: 7101.915469262773\n",
            "--------------------------\n",
            "iteration: 271\n",
            "cost: 7096.808736298963\n",
            "--------------------------\n",
            "iteration: 272\n",
            "cost: 7112.718294026636\n",
            "--------------------------\n",
            "iteration: 273\n",
            "cost: 7066.44830465924\n",
            "--------------------------\n",
            "iteration: 274\n",
            "cost: 7088.193216370184\n",
            "--------------------------\n",
            "iteration: 275\n",
            "cost: 7054.549496717564\n",
            "--------------------------\n",
            "iteration: 276\n",
            "cost: 7052.724020822675\n",
            "--------------------------\n",
            "iteration: 277\n",
            "cost: 7049.022142685562\n",
            "--------------------------\n",
            "iteration: 278\n",
            "cost: 7050.9000842008045\n",
            "--------------------------\n",
            "iteration: 279\n",
            "cost: 7054.175378449411\n",
            "--------------------------\n",
            "iteration: 280\n",
            "cost: 7043.515869563523\n",
            "--------------------------\n",
            "iteration: 281\n",
            "cost: 7053.7479645769545\n",
            "--------------------------\n",
            "iteration: 282\n",
            "cost: 7049.741088198422\n",
            "--------------------------\n",
            "iteration: 283\n",
            "cost: 7046.536949318055\n",
            "--------------------------\n",
            "iteration: 284\n",
            "cost: 7043.340454240536\n",
            "--------------------------\n",
            "iteration: 285\n",
            "cost: 7043.431586361798\n",
            "--------------------------\n",
            "iteration: 286\n",
            "cost: 7053.17395197198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "3UwGrUfF_RFP",
        "outputId": "ba4a5a85-b256-4aa7-e52f-0eb9ab594ab1"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(x_test, y_test)\n",
        "plt.plot(x_test, params_hat_batch[0] + params_hat_batch[1]*x_test, 'g', label='batch')\n",
        "plt.plot(x_test, params_hat[0] + params_hat[1]*x_test, '-r', label='stochastic')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(f'Batch      T0, T1: {params_hat_batch[0]}, {params_hat_batch[1]}')\n",
        "print(f'Stochastic T0, T1: {params_hat[0]}, {params_hat[1]}')\n",
        "# Calculate Root Mean Square error in batch gradient descent algorithm and stochastic gradient descent algorithm\n",
        "rms_batch = np.sqrt(1 / np.mean((params_hat_batch[0] + params_hat_batch[1] * x_test - y_test)**2))\n",
        "rms_stochastic = np.sqrt(1 / np.mean((params_hat[0] + params_hat[1] * x_test - y_test)**2))\n",
        "print(f'Batch RMS:      {rms_batch}')\n",
        "print(f'Stochastic RMS: {rms_stochastic}')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Batch      T0, T1: 27.861872599625915, 16.879079099843192\n",
            "Stochastic T0, T1: 19.156073855768767, 16.932601312557313\n",
            "Batch RMS:      0.0075121250583724914\n",
            "Stochastic RMS: 0.0072572794396348955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "r_tOykqS_RFP",
        "outputId": "6daf3319-207c-4ebd-d0fc-82e08492f735"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "plt.figure()\n",
        "plt.plot(np.arange(max_iter), cost_batch, 'r', label='batch')\n",
        "plt.plot(np.arange(len(cost)), cost, 'g', label='stochastic')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('normalized cost')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(f'min cost with BGD: {np.min(cost_batch)}')\n",
        "print(f'min cost with SGD: {np.min(cost)}')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "min cost with BGD: 6737.161195323204\n",
            "min cost with SGD: 7043.340454240536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QvTLwf_RFQ"
      },
      "source": [
        "### Ridge Regression\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{\\theta} = (X^TX + \\lambda I)^{-1}X^TY\n",
        "\\end{equation}\n",
        "\n",
        "where\n",
        "\\begin{equation}\n",
        "X = [\\bar{x}^T_1, \\bar{x}^T_2, ... , \\bar{x}^T_n]^T\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "Y = [y_1, y_2, ... , y_n]^T\n",
        "\\end{equation}\n",
        "\n",
        "This solution minimizes the following cost function\n",
        "\n",
        "\\begin{equation}\n",
        "J(x, \\theta, y) = \\sum_{i=1}^{m}(\\theta^T\\bar{x}_i - y_i)^2 + \\lambda ||\\theta||^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL0iqNj1_RFQ"
      },
      "source": [
        "class Ridge:\n",
        "    \"\"\"\n",
        "    Linear least squares with L2 regularization.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, lam):\n",
        "        \"\"\"\n",
        "        Initialize a Ridge object.\n",
        "        lam: the regularization factor \n",
        "        \"\"\"\n",
        "        self._lambda = lam\n",
        "        \n",
        "    @staticmethod\n",
        "    def _x_bar(x):\n",
        "        \"\"\"\n",
        "        Create the vector x_bar.\n",
        "        x: input vector\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        return np.hstack(([1.0], x, np.square(x)))\n",
        "        # End code here\n",
        "    \n",
        "    def fit(self, x_train, y_train):\n",
        "        \"\"\"\n",
        "        Generate a fit for the data.\n",
        "        x_train: the input values of the training data\n",
        "        y_train: the output values of the training data\n",
        "        \"\"\"\n",
        "        # Start code here\n",
        "        # stack the data\n",
        "        X = np.vstack(([self._x_bar(x) for x in x_train]))\n",
        "        Y = np.vstack(([y for y in y_train]))\n",
        "        \n",
        "        # compute the model coeff\n",
        "        XT = X.T\n",
        "        XTX = np.dot(XT, X) + self._lambda * np.identity(3)\n",
        "        XTX_inv = np.linalg.inv(XTX)\n",
        "        XTY = np.dot(XT, Y)\n",
        "        self._coeff_hat = np.dot(XTX_inv, XTY)\n",
        "        # End code here"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "x2HTbTxI_RFQ",
        "outputId": "a823a19e-a7d1-422d-bd4a-ab0aefb615d1"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "c2 = 0.03\n",
        "c1 = 1.25\n",
        "c0 = 3.23\n",
        "x_in = np.linspace(-15.0, 19.4, 250)\n",
        "y_out = c1 * x_in ** 2 + c1 * x_in + c0 + 400.0 * np.random.rand(len(x_in))\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(x_in, y_out)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9l81oIf_RFR"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "# Train using the custom Ridge class\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_in, y_out, test_size=0.20)\n",
        "\n",
        "lam = 0.1\n",
        "ridge = Ridge(lam)\n",
        "ridge.fit(x_train, y_train)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ED40E1L8_RFR",
        "outputId": "8cbddc8d-9668-481d-9440-fb3614244a17"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "# Plot test data and model predictions\n",
        "plt.figure()\n",
        "plt.scatter(x_test, y_test)\n",
        "x_test_sorted = np.sort(x_test)\n",
        "plt.plot(x_test_sorted,\n",
        "         ridge._coeff_hat[0] + ridge._coeff_hat[1]*x_test_sorted + ridge._coeff_hat[2]*x_test_sorted**2,\n",
        "         '-r', label='custom')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# print the coeff\n",
        "print(f'custom: {ridge._coeff_hat[0]}, {ridge._coeff_hat[1]}, {ridge._coeff_hat[2]}')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "custom: [192.84715707], [2.33470115], [1.30128135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ALhi46j_RFR"
      },
      "source": [
        "# Effect of regularization factor\n",
        "coeff_store = []\n",
        "norm_store = []\n",
        "factors = np.linspace(0.0, 1.0, 10)\n",
        "for l in factors:\n",
        "    # Star code here\n",
        "    # instantiate the Ridge class using l and store it in ridge\n",
        "    ridge = Ridge(l)\n",
        "    # fit the data to your model\n",
        "    ridge.fit(x_train, y_train)\n",
        "    # append co-effecients \n",
        "    coeff_store.append(ridge._coeff_hat)\n",
        "    # append normalized co-effecients using np.linalg.norm\n",
        "    norm_store.append(np.linalg.norm(ridge._coeff_hat))\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "UAkiEhAj_RFR",
        "outputId": "68c40574-51c8-4ced-a1b4-1087c02e3fa9"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "plt.figure()\n",
        "plt.subplot(411)\n",
        "coeff_0 = [c[0] for c in coeff_store]\n",
        "plt.plot(factors, coeff_0, 'or')\n",
        "plt.ylabel('c0')\n",
        "plt.subplot(412)\n",
        "coeff_1 = [c[1] for c in coeff_store]\n",
        "plt.plot(factors, coeff_1, 'og')\n",
        "plt.ylabel('c1')\n",
        "plt.subplot(413)\n",
        "coeff_2 = [c[2] for c in coeff_store]\n",
        "plt.plot(factors, coeff_2, 'ob')\n",
        "plt.ylabel('c2')\n",
        "plt.subplot(414)\n",
        "plt.plot(factors, norm_store, 'o')\n",
        "plt.xlabel('lambda')\n",
        "plt.ylabel('Norm')\n",
        "plt.show()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5RdZX3v8fdnMIHEACFM0kJgZuQi0EhAcIq0IuVHiywuGjRF5caiwmpaUK/Wwl1gVGgRBb204vW23CmNiEbEtsAFuZbFDWjUAosZgoRgUGgTIGlvEmJATJQf871/7D3m5HDOzDlnztl7z9mf11pnzTnP3mef75OZzHf2/u7neRQRmJmZVevJOwAzMysmJwgzM6vJCcLMzGpygjAzs5qcIMzMrCYnCDMzq+k1WX2QpOXAmcDmiDgybTsauA6YBawHlkTE85KOA4bG3gpcHhG3jnf83t7eGBgYaD6wbdtg40Z48UWYPh3mz4c5c5o/jpnZFDQyMrI1IubW2qasxkFIOhF4AbixIkE8CFwUEd+TdB7wuoj4lKSZwIsR8bKkA4AfAQdGxMv1jj84OBjDw8PNBbViBSxdCjt27GqbOROGhmDJkiZ7aGY29UgaiYjBWtsyu8QUEauAbVXNhwGr0ud3A4vTfXdUJIO9gM5ksWXLdk8OkLxetqwjH2dmNpXkXYNYCyxKn58NHDy2QdKbJa0F1gB/Ot7ZQ8ueeqq5djOzEsk7QZwHXChpBNgbeHFsQ0Q8EBFvAH4buFTSXtVvlrRU0rCk4S1btjT/6X19zbV3yooVMDAAPT3J1xUrsv18M7Mack0QEbEuIk6LiDcBNwFP1tjnxyS1iyNrbBuKiMGIGJw7t2aNZXxXXpnUHCrNnJm0Z2WsDrJhA0QkX5cudZIws9zlmiAkzUu/9gCfJLmjCUmvk/Sa9Hk/cATJXU7ttWRJUpDu7wcp+Zp1gdp1EDMrqCxvc70JOAnolfQMcBkwS9KH0l1uAb6SPj8BuETSS8AocGFEbO1IYEuW5HvHkusgZlZQmSWIiDinzqZra+z7NeBrnY2oIPr6kstKtdrNzHKUd5HailAHGeNiuZlVcILIWxHqIOBiuZm9SmYjqTutpZHUtsvAQO1LXf39sH591tGYWUYKMZLaCs7FcjOr4gRhiaIMGjSzwnCCsISL5WZWxQnCEi6Wm1kVF6mtWFwsN8uUi9Q2dbhYblYYThBWLC6WmxWGE4QVi4vlZoXRUoKQNEeSF2629nOx3KwwGi5SS+oDPg+cCmwHBOwD3ANcEhHrx3nvcuBMYHPFetRHk0zvPYtkKu8lEfG8pD8ArgKmkywgdHFE3DNRfC5SW1u5WG4l0a4i9c3ArcBvRsTrI+JQ4ADgNuCbE7z3BuD0qrbrSRLLwvS4F6ftW4G3p+3vpyyzulqxuFhu1lSC6I2ImyPilbGGiHglIr4J7D/eGyNiFbCtqvkwYFX6/G5gcbrv6ojYlLavBWZI2rOJOM0mr0jFctdCLCfNJIgRSX8j6c2SDkwfb5b0t8DqFj57LbAofX42cHCNfRYDD0XEr1o4vlnrilIsdy3EctRMgjgXWANcDtyVPi5P297XwmefB1woaQTYm6Te8GuS3gBcDfxJvQNIWippWNLwli1bWgjBrI6iFMu9JK3lqOmR1JJuBD4aET9LX+8HXBMR503wvgHg22NF6qpthwFfj4jj0tcHkRS/PxgRP2wkLheprSv19CRnDtUkGB3NPh7rOu0eSb1wLDkApM+PaSGoeenXHuCTJHc0IWk2cCdJAbuh5GDWtYpUC7HSaSVB9KRnDUAyJoIJ1raWdBNwH3C4pGcknQ+cI+knwDpgE/CVdPcPA4cCn5b0cPqY10KcZlNfUWoh4GJ5CY37i72Oa4D7JP1D+vpsYNyf1og4p86ma2vs+xngMy3EZdZ9xmoey5Ylt9j29SXJIa+Bg2P1kLFieWWM1nVams1V0gLglPTlPRHxWFujaoFrEGYd5IGDXWu8GkQrZxCkCSH3pGBmGfHAwVLyZH1mNjEXy0vJCcLMJlaUYrkL5ZlygjCziRVh4KBHlWfOS46a2dTgQnlHeMlRM5v6XCjPnBOEmU0NLpRnzgnCzKaGohTKoTTFcicIM5sailAoh1IVy12kNjNrRpcVy12kNjNrlxIVyzNJEJKWS9os6dGKtqMl3SdpjaQ7JO2Ttu8v6V5JL0j6chbxmZk1rEjF8g7XQrI6g7gBOL2q7XqSNR8WArcCF6ftvwQ+BVyUUWxmZo0rSrE8g1pIJgkiIlYB26qaDwNWpc/vJll/moj4RUT8gCRRmJkVS1GK5RksR9vSbK5tshZYBNxGsqbEwc0eQNJSYClAn++FNrOsLFmS/zoYGdRC8ixSnwdcKGkE2Bt4sdkDRMRQRAxGxODcuXPbHqCZWWFlUAvJLUFExLqIOC0i3gTcBDyZVyxmZlNOBrWQzMZBSBoAvh0RR6av50XEZkk9JEXs70bE8or9PwAMRsSHGzz+FqDGzckN6wW2TuL9U1HZ+ly2/oL73NV6Yc6BMH8aTH8JXtwEG7e+ut47kf6IqHkJJpMEIekm4CSSb9z/Ay4DZgEfSne5Bbg00mAkrQf2AaYD24HTOr2sqaTheoNFulXZ+ly2/oL7XBad6nMmReqIOKfOpmvr7D/QuWjMzKwRHkltZmY1OUHsMpR3ADkoW5/L1l9wn8uiI33umsn6zMysvXwGYWZmNZUqQUg6XdLjkp6QdEmN7XtKujnd/kB6a+6U1kCfPy7pMUmPSFopqT+PONtpoj5X7LdYUkia8ne8NNJnSe9Ov9drJX0j6xjbrYGf7b504s/V6c/3GXnE2S61Jj2t2i5JX0r/PR6RdOykPzQiSvEA9iAZjHcIye2zPwIWVO1zIXBd+vy9wM15x51Bn08GZqbPLyhDn9P99iaZC+x+kvE2ucfe4e/z64HVwH7p63l5x51Bn4eAC9LnC4D1ecc9yT6fCBwLPFpn+xnAdwABxwMPTPYzu6YG0dvbGwMDA029Z9vObWzYvoHRGP11W4966J/dz5wZc9ocoZlZ8YyMjGyNOgPl8pysr60GBgZodkW5gS8OMPrc6G5to4wyuu8owx/z6nRm1v0k1Z2BolQ1iGpPPVd71sN67WZmZVLqBNG3b+1ZD+u1m5mVSakTxJWnXsnMabvPhjhz2kyuPDXblaFWrFnBwBcH6PmLHga+OMCKNe1dNtDMrBWlThBLFi5h6O1D9O/bjxD9+/Yz9PYhlizMbiGQFWtWsPSOpWx4bgNBsOG5DSy9Y6mThJnlrmvuYhocHIxmi9RFMPDFATY89+oaUf++/az/2PrsAzKzUpE0EnVmgi31GUQRuFBuZkXlBJEzF8rNrKicIHJWlEI5uFhuZrvrWIKQdHA6D8rY3C8frbHPonTOkIclDUs6IW3vl/RQ2r5W0p92Ks68FaFQDi6Wm9mrdaxILekA4ICIeEjS3sAIcFZULB0qaRbwi4gISUcB34qIIyRNT2P7VbrPo8DvRsSmep83VYvUReFiuVk55VKkjoh/j4iH0uc/B34MzK/a54XYlaFeC0Ta/mJE/Cpt37OTcVrCxXIzq5bJL9502uxjgAdqbHunpHXAncB5Fe0HS3oEeBq4utbZg6Sl6aWp4S1btnQq/FJwsdzMqnU8QaSXiP4J+FhEPF+9PSJujYgjgLOAKyran46Io4BDgfdL+o0a7x2KiMGIGJw7t+ZkhNYgF8vNrFpHE4SkaSTJYUVE3DLevhGxCjhEUm9V+yaSGsRbOxaouVhuZq/SySK1gK8C2yLiY3X2ORR4Mi1SHwvcARxEUqt4NiJ2StqP5NLU4ohYU+/zXKTuDi6Wm2VrvCJ1J9eDeAvwR8AaSQ+nbZ8A+gAi4jpgMXCupJeAncB70mTxW8A1koJkdaT/Pl5ysO7hYrlZcXQsQUTED0h+uY+3z9XA1TXa7waO6lBoVmB9+/bVPIPIo1i+Ys0Klq1cxlPPPUXfvn1ceeqVmV9yM8uTbx+1QilKsdy1EDMnCCuYohTLl61cxo6XduzWtuOlHSxbuSzTOMzy1PIlJklrImJhO4MxgyRJ5H0px7UQswkShKR31dsE/Gb7wzErhiLVQszyMtElppuBdwBvr3qcCezV2dDM8lOUWgh44KDlZ6JLTI+Q3GL6aPUGSb/fmZDM8jd2iSvvu5jGiuVj9ZCxYnlljGadMu5AOUlvBTZExKsuvEoajIi6I9MkHQzcCPwGySR8QxFxbdU+i0im1xgFXiaZjuMHkt4I/C2wD/AKcGVE3DxeRzxQzrqRBw5ap7U8m2tEfD8inpL0VUmzKw64H3DhBJ/7MvDnEbEAOB74kKQFVfusBI6OiDeSTNR3fdq+Azg3It4AnA58sfLzzcrCxXLLU6O3uR4VEdvHXkTEz0hmZ61rktN9/yQifpo+3wRsBjwbn5WOZ9m1PDWaIHrSswYAJM2hiVtkW5nuu2L7ccB04Mka2zzdt3U1F8stT40miGuA+yRdIekK4F+Azzfyxlan+07fewDwNeCDETFa472e7tu6WlEGDnpkeTk1PJtrWj84JX15T+XSoeO8ZxrwbeCuiPirBvb/V+C4iNgqaR/gu8BnI+IfJ3qvi9RmneNiefdqy2yuaUKYMClUfKiAvwd+XC851Jjue0/g2XRN6luBGxtJDmbWWS6Wl1NRp/t+N3AisL+kD6Tv/UBEPIyZZc4jy8upqNN9fx34eodCM7MmXXnqlbsN2IP8ZtnNe/BimXg2VzObUBGK5S6UZ69jS45mzUVqs+7mQnlntDyS2sysKFwoz54ThJlNCUUaVV6WQYNOEGY2JRRlVHmZaiEdSxCSDpZ0r6THJK2V9NEa+yyS9Iikh9MpM06o2PbPkrZL+nanYjSzqaMIhXIo13K0HStSp9NkHBARD0naGxgBzqocgZ1Ow/GLdOzDUcC30mk3kHQqMBP4k4g4c6LPc5HazLLQ8xc9BK/+vSnE6GWvmhGo8HIpUk9mNtd020rg552Kz8ysFUWqhXRaJjWIyczmamZWJEWphUDni+UdTxCTmc21gWN7um8zy1RRaiFZFMs7OlBuMrO5pq9PAi5yDcLMbHftGjiYSw2i0dlc0/2onM21UzGZmXWLLAYOFnI2VwBJ3weOAGZJegY4PyLu6mC8ZmZTRhYz7HbNXEyStgCv/tdqXC+wtU3hTBVl63PZ+gvuc/eayRz2pZ/drwSN8hwb2MG2Jo7UHxE1l+TsmgQxWZKG612H61Zl63PZ+gvuc1l0qs+easPMzGpygjAzs5qcIHYZyjuAHJStz2XrL7jPZdGRPrsGYWZmNfkMwszManKCMDOzmkqVICSdLulxSU9IuqTG9j0l3ZxufyCdZHBKa6DPH0/X7HhE0kpJ/XnE2U4T9bliv8WSQtKUvyWykT5LenfF+izfyDrGdmvgZ7svXZNmdfrzfUYecbaLpOWSNkt6tM52SfpS+u/xSDo7xeRERCkewB7Ak8AhwHTgR8CCqn0uBK5Ln78XuDnvuDPo88nAzPT5BWXoc7rf3sAq4H5gMO+4M/g+vx5YDeyXvp6Xd9wZ9HkIuCB9vgBYn3fck+zzicCxwKN1tp8BfAcQcDzwwGQ/s2uK1L29vTEwMJB3GGZmmdi2DTZsgNGKNYp6eqC/H+bMafw4IyMjW6POSOpOzsWUqYGBATybq5mVxcDA7skBktejo9DMr0JJdacoKlUNwsysWzxVZ9LWeu2tcIIwM5uC+upM2lqvvRWdXA9ioor7orTS/nC6KtwJFdv+WdJ2Sd/uVHxmZq1asSK5xNPTk3xd0d6VPhty5ZUwc/eVT5k5M2lvl06eQdwAnD7O9pXA0RHxRpK1qK+v2PYFkrUkzMwKZcUKWLo0KRBHJF+XLs0+SSxZAkNDSVFaSr4ODSXt7dKxBBERq6D+nOQR8ULsuoXqtUBUbFsJ/LxTsZmZtWrZMtixY/e2HTuS9qwtWQLr1yeF6fXr25scIOcahKR3SloH3ElyFtHs+5eml6eGt2zZ0v4AzcyqZFEcLopcE0RE3BoRRwBnAVe08P6hiBiMiMG5c2vexmtmXaQI1/6zKA4XRSHuYkovRx0iqTfvWMysmIpy7T+L4nBR5JYgJB0qSenzY4E9gWfzisfMiq0o1/6zKA4XRcdGUku6CTgJ6JX0DHAZMA0gIq4DFgPnSnoJ2Am8Z6xoLen7wBHArPS950fEXZ2K1cyKr0jX/pcs6c6EUK1jCSIizplg+9XA1XW2vbUjQZnZlNXXl1xWqtVunVGIGoSZFV/eBeIyXfsvCicIM5tQEQrEZbr2XxRdM9334OBgeDZXs84YGKh9eae/PxmgZVOXpJGIqLlols8gzGxCRSoQW3acIMxsQmUaHGa7OEGYFVzexWFwgbisnCDMCqwIxWFwgbisXKQ2KzAXh63TWi5SSzpY0jclfV/SJyRNq9h2W7sDNbPduThseZroEtNy4LvAR4ADgO9J2j/d1t/BuMwMF4ctXxMliLkRcV1EPBwRHwH+Blgl6T9RscCPWTdycdjKbqK5mKZJ2isifgkQEV+X9B/AXSSrwJl1pbHi8NjsoWPFYci2MDv2WcuWJZeV+vqS5ODisGVh3CK1pD8DHoqI71W1HwN8PiL+oMPxNcxFamsnF4etLFouUkfEX0fE9yR9VdLsik3rgafbGKNZobg4bNb4OIijImL72IuI+BlwTGdCMsufi8NmjSeIHkn7jb2QNIcOriVh5ebisFkxNPpL/hrgPkn/kL4+G/B/FWs7F4fNiqPhkdSSFgCnpC/viYjHOhZVC1yk7g4uDptla7widcOXidKEUKikYN3HxWGz4vBkffZrRbj27+KwWXE4QRhQnFlDXRw2Kw4nCAOSYuxYYXjMjh1Je5Y8rbRZcXi6bwOSy0q1fhQkGB3NPh4zy4bXpLYJ+dq/mVVzgiiAIhSHfe3fzKo5QeSsKMVhX/s3s2quQeTMA8PMLE+uQRSYB4aZWVE5QeTMxWEzK6qOJQhJyyVtlvRone2LJD0i6WFJw5JOqNj2fkk/TR/v71SMkH+B2MVhMyuqTp5B3ACcPs72lcDREfFG4Dzgevj1VOKXAW8GjgMuq5xqvJ2KUCB2cdjMiqpjCSIiVgHbxtn+QuyqkL8WGHv+NuDuiNiWLkx0N+MnmpYVafTw+vXJgLT1650czKwYcq1BSHqnpHXAnSRnEQDz2X0502fStlrvX5penhresmVL05/vArGZWX25JoiIuDUijgDOAq5o4f1DETEYEYNz585t+vNdIDYzq68Qy4ZGxCpJh0jqBTYCJ1VsPgj47kTHGBkZ2SqpxoiC8fTOgb5+UEWijNENG57aIG2te3msi/QCW/MOIkNl6y+4z2UxmT7319uQW4KQdCjwZESEpGOBPYFngbuAz1YUpk8DLp3oeBHR/CnE7vEM1xss0q3K1uey9Rfc57LoVJ87liAk3URyJtAr6RmSO5OmAUTEdcBi4FxJLwE7gfekRettkq4AHkwP9ZcRUYa/5s3MCqVjCSIizplg+9XA1XW2LQeWdyIuMzNrjEdS7zKUdwA5KFufy9ZfcJ/LoiN97prJ+szMrL18BmFmZjU5QZiZWU2lShCSTpf0uKQnJF1SY/uekm5Otz8gaSD7KNurgT5/XNJj6cSJKyXVvSd6qpiozxX7LZYUkqb8LZGN9FnSu9Pv9VpJ38g6xnZr4Ge7T9K9klanP99n5BFnuzQwAaokfSn993gkHT4wORFRigewB/AkcAgwHfgRsKBqnwuB69Ln7wVuzjvuDPp8MjAzfX5BGfqc7rc3sAq4HxjMO+4Mvs+vB1YD+6Wv5+UddwZ9HgIuSJ8vANbnHfck+3wicCzwaJ3tZwDfAQQcDzww2c/MrEgtaTlwJrA5Io5M244GrgNmAeuBJRHxvKTj2FWVF3B5RNw63vF7e3tjYGCgqZi273iJjdt3Mlrxb9AjMX/2DGbPnNbUsczMpqKRkZGtUWegcZYJ4kTgBeDGigTxIHBRRHxP0nnA6yLiU5JmAi9GxMuSDiD56+DAiHi53vFbWXL0LVfdw8btO1/VPn/2DH54ySlNHcvMbCoqxJKjUXv678NITvMhmdZ7cbrvjopksBe7pgJvq001ksN47WZmZZJ3kXotsCh9fjZw8NgGSW+WtBZYA/xprbOHyU73feDsGU21d8ptqzfylqvu4XWX3MlbrrqH21ZvzPTzzcxqyTtBnAdcKGmEpGj44tiGiHggIt4A/DZwqaS9qt8ck5zu++K3Hc6MaXvs1jZj2h5c/LbDmz5Wq25bvZFLb1nDxu07CWDj9p1cessaJwkzy13e60Gsi4jTIuJNwE0kdyVU7/NjktrFke3+/LOOmc/n3rWQ+bNnIJLaw+fetZCzjqm5PlFHfOGux9n50iu7te186RW+cNfjmcVgZlZLrutBSJoXEZsl9QCfJLmjCUmvA55Oi9T9wBEkdzm13VnHzM80IVRzHcTMiiqzM4h0+u/7gMMlPSPpfOAcST8B1gGbgK+ku58A/EjSw8CtwIUR0ZULgBSlDmJmVi2zM4ioP/33tTX2/Rrwtc5GVAwXv+1wLr1lzW6XmbKug4y5bfVGvnDX42zavpMDZ8/g4rcdnuvZlZnlqxBLjpbZ2C/gvH8xjxXLxxLVWLG8MkYzKxcniALIuw4C4xfL847NzPKR922uVhAulptZtZbOICQdBQxUvj8ibmlTTJaDA2fPqDntiIvlZuXVdIJIJ907imQU9GjaHIATxBTmYrmZVWvlDOL4iFjQ9kgsVy6Wm1m1VhLEfZIWRMRjbY/GcuViuZlVaiVB3EiSJP4D+BXJeg0REUe1NTIrJRfLzYqjlQTx98AfkcyyOjrBvmZNcbHcrDhaSRBbIuL2tkdihovlZkXSSoJYnS54fgfJJSbAt7lae7hYblYcrSSIGSSJ4bSKNt/mam3jYrlZMTSVICTtATwbERc1+b7lwJnA5or1qI8mmd57FslU3ksi4nlJfwBcBUwnWUDo4oi4p5nPM5ssF8vNmpxqIyJeAd7SwufcAJxe1XY9cElELCSZ0vvitH0r8Pa0/f2UZFZXKxZPw27W2lxMD0u6XdIfSXrX2GO8N0TEKmBbVfNhwKr0+d3A4nTf1RGxKW1fC8yQtGcLcZq1rAjL0Y7xmuWWl1ZqEHsBzwKnVLS1UoNYCywCbgPOBg6usc9i4KGI+FWNbUhaCiwF6Ovra/LjzepzsdwMFBHZfJA0AHy7ogZxBPAlYH/gduC/RsT+Ffu/IW0/LSJetVZ1tcHBwRgeHu5A5Gb5ectV99QcFzJ/9gx+eMkpNd5h1hxJIxExWGtb05eYJB0k6VZJm9PHP0k6qNnjRMS6iDgtIt4E3AT8Ogmkx7sVOLeR5GDWrVwstzy1UoP4Cslf9gemjzvYtZZ0wyTNS7/2AJ8kuaMJSbOBO0kK2D9sIT6zrlGkYrlrIeXTSoKYGxFfiYiX08cNwNzx3iDpJuA+4HBJz0g6HzhH0k+AdcAmdiWZDwOHAp+W9HD6mNdCnGZTXlGK5WO1kI3bdxLsqoU4SXS3VorUz0p6H8llIYBzSIrWdUXEOXU2XVtj388An2khLrOuU5RiuQcOllMrCeI84H8Af01y99K/AB9sZ1BmtksRRpa7FlJOTSeIiNgAvKMDsZhZQXmW3XJqOEFI+vQ4myMirmhDPGZWQEWZZdcz7GarmTOIX9Roey1wPslYBicIsy5VhFqIBw1mr6WBcpL2Bj5Kkhy+BVwTEZvbHFtTPFDOrLt50GBnjDdQrtnZXOcAHweWAF8Fjo2In00+RDOz8blQnr2Gx0FI+gLwIPBzYGFEXO7kYGZZKdKgwbJoZqDcn5OMnP4ksEnS8+nj55Ke70x4ZmaJogwahPKMKm/4ElNEtDLq2sysLYpQKIdyFctbGShnZpaLIgwaLNOocp8VmJk1oUzFcicIM7MmlKlYnkmCkLQ8XTvi0Yq2oyXdJ2mNpDsk7ZO27y/pXkkvSPpyFvGZmTWqTMXyrM4gbgBOr2q7nmTNh4UkiwNdnLb/EvgUcFFGsZmZNeysY+bzuXctZP7sGYhkoN7n3rUwt2J5J6dgz6RIHRGr0iVHKx0GrEqf3w3cBXwqIn4B/EDSoVnEZmbWrLIUy/OsQawFFqXPzwYObvYAkpZKGpY0vGXLlrYGZ2ZWZFkUy/NMEOcBF0oaAfYGXmz2ABExFBGDETE4d+64i9qZmXWVLIrluY2DiIh1wGkAkg4D/vNkjjcyMrJV0oZJHKIX2DqZGKagsvW5bP0F97lr9czYZ85r9pnbj7TrD/2I0aef37JBlz6/rYlD9dfbkFuCkDQvIjYr6dwngesmc7yImNQphKThejMadquy9bls/QX3uSw61edMEoSkm4CTgF5JzwCXAbMkfSjd5RbgKxX7rwf2AaZLOgs4LSIeyyJWMzNLZHUX0zl1Nl1bZ/+BzkVjZmaN8EjqXYbyDiAHZetz2foL7nNZdKTPLa0oZ2Zm3c9nEGZmVlOpEoSk0yU9LukJSZfU2L6npJvT7Q/UGP095TTQ549LekzSI5JWSqp7y9tUMVGfK/ZbLCkkTfk7Xhrps6R3p9/rtZK+kXWM7dbAz3ZfOq/b6vTn+4w84myXWnPaVW2XpC+l/x6PSDp20h8aEaV4AHsATwKHANOBHwELqva5ELguff5e4Oa8486gzycDM9PnF5Shz+l+e5NM9XI/MJh33Bl8n18PrAb2S1/PyzvuDPo8BFyQPl8ArM877kn2+UTgWODROtvPAL4DCDgeeGCyn1mmM4jjgCci4l8j4kXgm+ya6mPMIuCr6fN/BE6VpAxjbLcJ+xwR90bEjvTl/cBBGcfYbo18nwGuAK4mmRxyqmukz38M/M9I15GPiM0Zx9hujfQ5SG6XB9gX2JRhfG0XEauA8QbALQJujMT9wGxJB0zmM8uUIOYDT1e8fiZtq7lPRLwMPAfsn0l0ndFInyudT/IXyFQ2YZ/TU++DI+LOLAProEa+z4cBh0n6oaT7JVXPrjzVNNLny4H3pWOv/g/wkWxCy02z/98n5CVHDQBJ7wMGgd/LO5ZOSkfu/xXwgZxDydprSC4znURylrhK0sKI2J5rVJ11DnBDRFwj6XeAr0k6MiJG8wSGS8QAAANQSURBVA5sqijTGcRGdp8x9qC0reY+kl5Dclr6bCbRdUYjfUbS7wPLgHdExK8yiq1TJurz3sCRwHfTEfvHA7dP8UJ1I9/nZ4DbI+KliPg34CckCWOqaqTP5wPfAoiI+4C9SOZp6lYN/X9vRpkSxIPA6yW9TtJ0kiL07VX73A68P33+h8A9kVZ/pqgJ+yzpGOB/kSSHqX5dGiboc0Q8FxG9ETEQyYj9+0n6PpxPuG3RyM/2bSRnD0jqJbnk9K9ZBtlmjfT5KeBUAEm/RZIgunldgNuBc9O7mY4HnouIf5/MAUtziSkiXpb0YZKFifYAlkfEWkl/CQxHxO3A35Ochj5BUgx6b34RT16Dff4CMAv4h7Qe/1REvCO3oCepwT53lQb7fBdwmqTHgFeAiyNiyp4dN9jnPwf+TtKfkRSsPzCV/+CrM6fdNICIuI6kznIG8ASwA/jgpD9zCv97mZlZB5XpEpOZmTXBCcLMzGpygjAzs5qcIMzMrCYnCDMzq8kJwmwckl5o03Eul3RRA/vdIOkP2/GZZpPlBGFmZjU5QZg1QNKsdL2MhyStkbQobR+QtC79y/8nklZI+v10UryfSjqu4jBHS7ovbf/j9P2S9OV0XYP/C8yr+MxPS3pQ0qOShqb4zMI2BTlBmDXml8A7I+JYkjU0rqn4hX0ocA1wRPr4L8AJwEXAJyqOcRRwCvA7wKclHQi8EzicZL2Cc4Hfrdj/yxHx2xFxJDADOLNDfTOrqTRTbZhNkoDPSjoRGCWZRvk30m3/FhFrACStBVZGREhaAwxUHON/R8ROYKeke0nWNDgRuCkiXgE2SbqnYv+TJf03YCYwB1gL3NGxHppVcYIwa8wSYC7wpoh4KZ0Jdq90W+UMuKMVr0fZ/f9Y9bw2dee5kbQX8Dckq909Lenyis8zy4QvMZk1Zl9gc5ocTgZaWbt7kaS9JO1PMunagyTLnr5H0h7p6l8np/uOJYOtkmaRzC5slimfQZg1ZgVwR3rZaBhY18IxHgHuJVmT4IqI2CTpVpK6xGMk01PfBxAR2yX9HfAo8B8kycQsU57N1czMavIlJjMzq8kJwszManKCMDOzmpwgzMysJicIMzOryQnCzMxqcoIwM7OanCDMzKym/w+2a0SZzTgr6gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZr2pvb_RFS"
      },
      "source": [
        "### Q3. Theory (10 marks)\n",
        "\n",
        "Consider training a binary decision tree using entropy splits.\n",
        "\n",
        "(a) Prove that the decrease in entropy by a split on a binary yes/no feature can never be greater than 1 bit.\n",
        "\n",
        "(b) Generalize this result to the case of arbitrary multiway branching."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ0U170zGDHw"
      },
      "source": [
        "(a) Use d denotes dataset, the entropy of the original dataset is H(d)\n",
        "\n",
        "$H(D) = - \\sum_{i}{P(D_i)\\log_2 (P(D_i))} $\n",
        "\n",
        "Split the dataset into two features $F = (f_l, f_r)$, the entropy for the two child nodes can be calculated as:\n",
        "\n",
        "$$P(f_l)H(L) + P(f_r)H(R) = - P(f_l) \\sum_{i}(P(d_i | f_l) * log_2(P(d_i|f_l)) )- P(f_r) \\sum_{i}(P(d_i|f_r)*log_2(P(d_i|f_r)))$$\n",
        "\n",
        "where,\n",
        "\n",
        "$$P(d_i | f_l) = \\frac{P(d_i, f_l)}{P(f_l)}, P(d_i | f_r) = \\frac{P(d_i, f_r)}{P(f_r)}$$\n",
        "\n",
        "so,\n",
        "\n",
        "   $$P(f_l)H(L) + P(f_r)H(R) = - P(f_l) \\sum_{i}(\\frac {P(d_i, f_l)}{P(f_l)} * log_2(\\frac {P(d_i, f_l)}{P(f_l)}) )- P(f_r) \\sum_{i}(\\frac {P(d_i, f_r)}{P(f_r)}*log_2(\\frac {P(d_i, f_r)}{P(f_r)}))$$\n",
        "\n",
        "   $$P(f_l)H(L) + P(f_r)H(R) = - \\sum_{i}( P(d_i, f_l) * log_2(\\frac {P(d_i, f_l)}{P(f_l)} ))-  \\sum_{i}( P(d_i, f_r)*log_2(\\frac {P(d_i, f_r)}{P(f_r)}))$$\n",
        "\n",
        "   $$P(f_l)H(L) + P(f_r)H(R) = - \\sum_{i}( P(d_i, f_l) * log_2( P(d_i, f_l) - log_2 {P(f_l)}))-  \\sum_{i}( P(d_i, f_r)*log_2(P(d_i, f_r) - log_2(P(f_r)))$$\n",
        "\n",
        "   $$P(f_l)H(L) + P(f_r)H(R) = - \\sum_{i}( P(d_i, f_l) * log_2( P(d_i, f_l))) + \\sum_{i}(P(d_i, f_l) * log_2 {P(f_l)})-   \\sum_{i}( P(d_i, f_r) * log_2( P(d_i, f_r))) + \\sum_{i}(P(d_i, f_r) * log_2 {P(f_r)}) $$\n",
        "\n",
        "where,\n",
        "\n",
        "$$\\sum_{i}(P(d_i, f_l) = P(f_l),  \\sum_{i}(P(d_i, f_r) = P(f_r) $$\n",
        "\n",
        "so,\n",
        "\n",
        "   $$P(f_l)H(L) + P(f_r)H(R) = - \\sum_{i}( P(d_i, f_l) * log_2( P(d_i, f_l))) - \\sum_{i}( P(d_i, f_r) * log_2( P(d_i, f_r))) + P(f_l) * log_2 {P(f_l)} +P(f_r) * log_2 {P(f_r)} $$\n",
        "\n",
        "$$P(f_l)H(L) + P(f_r)H(R) = H(D, F) - H(F)$$\n",
        "\n",
        "So the decrease in entropy is \n",
        "\n",
        "$$ \\Delta H = H(D) - P(f_l)H(L) + P(f_r)H(R)$$\n",
        "\n",
        "$$ \\Delta H = H(D) - H(D, F) + H(F)$$\n",
        "\n",
        "since \n",
        "\n",
        "$$H(D) - H(D, F) \\leq 0$$\n",
        "and it is a yes/no binary split, For the maximum H(F)\n",
        "\n",
        "$$ H(F)_{max} = - \\frac{1}{2}log_2(\\frac {1}{2}) -  - \\frac{1}{2}log_2(\\frac {1}{2})  = 1 \\space bit  $$\n",
        "\n",
        "$$H(F) \\leq  1 \\space bit$$\n",
        "\n",
        "$$H(D) - H(D, F) + H(F) \\leq 1 \\space bit$$\n",
        "\n",
        "so,\n",
        "$$ \\Delta H = H(D) - H(D, F) + H(F) \\leq 1 \\space bit$$\n",
        "\n",
        "So decrease in entropy by a split on a binary yes/no feature can never be greater than 1 bit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o-0DiVpGD49"
      },
      "source": [
        "(b) Similarly for n way branching\n",
        "Use d denotes dataset, the entropy of the original dataset is H(d)\n",
        "\n",
        "$$H(D)=_iP(D_i)log_2(P(D_i))$$\n",
        "\n",
        "Split the dataset into n features $F = (f_1, f_2, ... f_n)$, the entropy for all the child nodes can be calculated as:\n",
        "\n",
        "$$P(f_1)H(D_1) + P(f_2)H(D_2) + ... + P(f_n)H(D_n) = H(D, F) - H(F)$$\n",
        "\n",
        "$$\\Delta H = H(D) - H(D, F) + H(F) \\leq H(F)$$\n",
        "\n",
        "where,\n",
        "\n",
        "$$H(F)_{max} = -\\frac{1}{n} log_2 (\\frac {1}{n}) * n = log_2 (n)$$\n",
        "\n",
        "$$\\Delta H \\leq log_2 (n)$$\n",
        "\n",
        "So decrease in entropy by a split on a n way branching can never be greater than $log_2(n)$ bit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdQ-hKmk_RFS"
      },
      "source": [
        "### Q4. Gradient Descent Application (10 marks)\n",
        "\n",
        "1. For the function \\begin{equation} f(x, y) = ln(1 + xy), \\end{equation}\n",
        "find the unit vector that gives the direction of steepest descent at the point\n",
        "P (2, 3). Also find the direction of no change at this point.\n",
        "\n",
        "\n",
        "2. A businessperson can sell a product in France and Japan and charge different prices in each region. Let x represent the number of units sold in France and y represent the number of units sold in Japan. According to demand rules, the business owner must set the unit price at 97-(x/10) dollars in France and 83-(y/20) dollars in Japan in order to sell all of the units. The cost of production is ${\\$ 3}$ per unit, in addition to a base capital of ${\\$ 20,000}.$ If the industrialist intends to maximize profit, how many units should he aim to sell in each country?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DLB4Zf4GJIf"
      },
      "source": [
        "1. $f(x, y) = ln(1 + xy)$\n",
        "\n",
        "   $\\nabla f (x, y) = (\\frac{\\partial f}{\\partial x_1} , \\frac{\\partial f}{\\partial x_2} )= (\\frac {y}{1+xy}, \\frac {x}{1+xy}) $ \n",
        "\n",
        "   At point P(2, 3)\n",
        "\n",
        "   $ \\nabla f(2, 3) = (\\frac {3}{7}, \\frac{2}{7})$\n",
        "\n",
        "   The steepest descent vector $\\hat u$\n",
        "\n",
        "   $\\hat u = -\\nabla f(2, 3) = (-\\frac {3}{7}, -\\frac{2}{7})$\n",
        "\n",
        "   The unit steepest descent vector $\\hat i$\n",
        "\n",
        "   $\\hat i = \\frac {\\hat u}{\\Vert \\hat u \\Vert} = (-\\frac {3}{7} * \\frac{1}{\\sqrt{(-\\frac {3}{7})^2 + (-\\frac {2}{7})^2}}, -\\frac {2}{7} * \\frac{1}{\\sqrt{(-\\frac {3}{7})^2 + (-\\frac {2}{7})^2}})$\n",
        "\n",
        "    $\\hat i = (-\\frac{3}{\\sqrt{13}}, -\\frac{2}{\\sqrt{13}})$\n",
        "\n",
        "    The unit vector pf the direction of no change at the point P(2, 3), $\\hat v$\n",
        "\n",
        "    $\\hat v$ should be otthogonal to $\\hat i$ so that there is no change at the point P(2, 3) at the direction of $\\hat v$, o\n",
        "\n",
        "    $\\hat v \\cdot \\hat i = 0 $\n",
        "\n",
        "    $\\hat v = (\\frac {2}{\\sqrt {13}}, \\frac {-3}{\\sqrt {13}})$\n",
        "\n",
        "    The unit vector that gives the direction of steepest descent at the point P (2, 3) is $\\hat i = (-\\frac{3}{\\sqrt{13}}, -\\frac{2}{\\sqrt{13}})$\n",
        "\n",
        "     The unit vector that gives that gives no change at this point is $\\hat v = (\\frac {2}{\\sqrt {13}}, \\frac {-3}{\\sqrt {13}})$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH823QLAGKXK"
      },
      "source": [
        "2. The profit can be calculated as \n",
        "\n",
        "  profit = Price_in_France * units_sold_in_France + Price_in_Japan * units_sold_in_Japan - cost_per_unit * total_unit_sold - base_capital\n",
        "\n",
        "  So the profit f(x, y) is:\n",
        "\n",
        "  $f(x, y) = (97 - \\frac {x}{10}) * x + (83 - \\frac{y}{20}) * y - 3 * (x + y) - 20000$\n",
        "\n",
        "  $f(x, y) = - \\frac {x^2}{10} + 94x + - \\frac{y^2}{20} + 80y - 20000$\n",
        "\n",
        "  The partial derivative is:\n",
        "  \n",
        "  $f_x = \\frac {\\partial f}{\\partial x} = -\\frac {x}{5} + 94$\n",
        "\n",
        "  $f_y = \\frac {\\partial f}{\\partial y} = -\\frac {y}{10} + 80$\n",
        "\n",
        "  $f_{xx} = \\frac {\\partial^2 f}{\\partial x^2 } = -\\frac {1}{5}$\n",
        "\n",
        "  $f_{yy} = \\frac {\\partial^2 f}{\\partial y^2} = -\\frac {1}{10}$\n",
        "\n",
        "  $f_{xy} = \\frac {\\partial^2 f}{\\partial x \\partial y} = 0$\n",
        "\n",
        "  $\\nabla f(x, y) = (f_x, f_y) = (-\\frac {x}{5} + 94,  -\\frac {y}{10} + 80)$\n",
        "\n",
        "  Let $f_x = 0, f_y = 0$, the only solution is:\n",
        "\n",
        "  x = 470, y = 800\n",
        "\n",
        "  (470, 800) is a stationary point and only stationary point for f(x, y)\n",
        "\n",
        "  Since,\n",
        "\n",
        "  $f_{xx} < 0$ and $ f_{yy} < 0$,\n",
        "  \n",
        "  so (470, 800) is a maximum point for f(x, y)\n",
        "\n",
        "  So to get the maximum profit, the business person should sell 470 units in France and 800 units in Japan\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBcChtH_RFS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}